# -*- coding: utf-8 -*-
"""swinsimCLR.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1CpsbuoCMVJXzeWWmVUw1HE0AWANQPcNK
"""

# -*- coding: utf-8 -*-
"""
ë…¼ë¬¸ ê¸°ë°˜ ë©€í‹°í•´ìƒë„ CXR ì´ìƒ íƒì§€ ëª¨ë¸
- FAISS ì œê±°, Mahalanobis ê±°ë¦¬ ê³„ì‚°
- ë°°ì¹˜ ì¶•ì  í•™ìŠµ (128,256: ë°°ì¹˜4, 512,1024: ë°°ì¹˜2)
- ë…¼ë¬¸ ë°©ì‹ ì´ìƒì ìˆ˜ ê³„ì‚° (patch distance íŒŒë¼ë¯¸í„° ì ìš©)
- í ì˜ì—­ ë§ˆìŠ¤í¬ ë° K-fold ì œê±°
"""

import os
import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
import torchvision.transforms as transforms
from torchvision.models import swin_t, Swin_T_Weights
import numpy as np
import pandas as pd
from PIL import Image
import cv2
from tqdm import tqdm
import matplotlib.pyplot as plt
import logging
import json
import pickle
from datetime import datetime
from sklearn.metrics import roc_curve, auc, roc_auc_score, accuracy_score, precision_score, recall_score, confusion_matrix
from sklearn.covariance import EmpiricalCovariance

# GPU ì„¤ì •
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
print(f"ğŸš€ Using device: {device}")

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# ===================================================================
# Configuration
# ===================================================================

class PaperBasedConfig:
    """ë…¼ë¬¸ ê¸°ë°˜ ì„¤ì • í´ë˜ìŠ¤"""
    def __init__(self):
        # ë°ì´í„° ê²½ë¡œ
        self.image_base_path = "/content/drive/MyDrive/CXR8/images"
        self.csv_path = "/content/drive/MyDrive/CXR8/Data_Entry_2017_v2020.csv"
        self.save_dir = "/content/drive/MyDrive/last_results"

        # ë…¼ë¬¸ì˜ ë©€í‹°í•´ìƒë„ íŒ¨ì¹˜ ì„¤ì •
        self.patch_sizes = [128, 256]

        # ë…¼ë¬¸ì˜ ë°°ì¹˜ ì„¤ì • (128,256: 4ë°°ì¹˜, 512,1024: 2ë°°ì¹˜)
        self.batch_configs = {
            128: {'batch_size': 64, 'accumulation_steps': 4},
            256: {'batch_size': 64, 'accumulation_steps': 4},
        }

        # í•™ìŠµ ì„¤ì •
        self.max_normal_images = 1000
        self.max_abnormal_images = 100
        self.epochs = 10
        self.learning_rate = 3e-4
        self.weight_decay = 1e-4

        # Swin-Tiny ëª¨ë¸ ì„¤ì •
        self.backbone = 'swin_tiny'
        self.feature_dim = 768
        self.projection_dim = 128  # ë…¼ë¬¸ê³¼ ë™ì¼
        self.temperature = 0.1

        # ë…¼ë¬¸ì˜ ë©€í‹°í•´ìƒë„ ìœµí•© ê°€ì¤‘ì¹˜
        self.resolution_weights = {128: 0.1, 256: 1.2, 512: 1.2, 1024: 1.0}

        # ë…¼ë¬¸ì˜ patch distance íŒŒë¼ë¯¸í„°
        self.patch_distance_params = {128: 2, 256: 1, 512: 0, 1024: 0}

        # ì´ìƒ íƒì§€ ì„ê³„ê°’
        self.anomaly_threshold = 0.38

        # ê¸°íƒ€
        self.device = device
        self.num_workers = 4

config = PaperBasedConfig()

# ===================================================================
# ë‹¨ì¼ í•´ìƒë„ Swin SimCLR ëª¨ë¸
# ===================================================================

class SingleResolutionSwinSimCLR(nn.Module):
    """ë‹¨ì¼ í•´ìƒë„ìš© Swin-Tiny SimCLR ëª¨ë¸ (ë…¼ë¬¸ ê¸°ë°˜)"""

    def __init__(self, patch_size, feature_dim=768, projection_dim=128):
        super(SingleResolutionSwinSimCLR, self).__init__()

        self.patch_size = patch_size
        self.feature_dim = feature_dim
        self.projection_dim = projection_dim

        # Swin-Tiny ë°±ë³¸
        swin = swin_t(weights=Swin_T_Weights.IMAGENET1K_V1)
        self.encoder = nn.Sequential(*list(swin.children())[:-1])

        # Projection head (ë…¼ë¬¸ì˜ SimCLR êµ¬ì¡°)
        self.projection = nn.Sequential(
            nn.Linear(feature_dim, feature_dim),
            nn.ReLU(inplace=True),
            nn.Linear(feature_dim, projection_dim)
        )

        self._initialize_weights()

    def _initialize_weights(self):
        for m in self.modules():
            if isinstance(m, nn.Linear):
                nn.init.trunc_normal_(m.weight, std=0.02)
                if m.bias is not None:
                    nn.init.constant_(m.bias, 0)

    def forward(self, x):
        # íŠ¹ì§• ì¶”ì¶œ
        h = self.encoder(x)
        # Projection
        z = self.projection(h)
        # L2 ì •ê·œí™”
        return F.normalize(z, dim=-1)

    def get_features(self, x):
        """íŠ¹ì§• ì¶”ì¶œ (projection ì´ì „)"""
        with torch.no_grad():
            h = self.encoder(x)
        return h

# ===================================================================
# í•´ìƒë„ë³„ ë°ì´í„°ì…‹
# ===================================================================

class SingleResolutionDataset(Dataset):
    """ë‹¨ì¼ í•´ìƒë„ìš© ë°ì´í„°ì…‹ (ë…¼ë¬¸ ë°©ì‹)"""

    def __init__(self, image_list, patch_size, config, is_training=True):
        self.image_list = image_list
        self.patch_size = patch_size
        self.config = config
        self.is_training = is_training

        # í•´ë‹¹ í•´ìƒë„ì˜ íŒ¨ì¹˜ë§Œ ì¶”ì¶œ
        self.patches = self._extract_patches()

        # ë³€í™˜ ì •ì˜
        self.transform = self._get_transforms()

    def _get_transforms(self):
        if self.is_training:
            return transforms.Compose([
                transforms.ToPILImage(),
                transforms.Resize((self.patch_size, self.patch_size)),
                transforms.RandomHorizontalFlip(p=0.5),
                transforms.RandomRotation(degrees=(-5, 5)),  # ë…¼ë¬¸: -5ë„ ~ +5ë„
                transforms.ToTensor(),
                transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
            ])
        else:
            return transforms.Compose([
                transforms.ToPILImage(),
                transforms.Resize((self.patch_size, self.patch_size)),
                transforms.ToTensor(),
                transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
            ])

    def _extract_patches(self):
        """ë…¼ë¬¸ ë°©ì‹ íŒ¨ì¹˜ ì¶”ì¶œ"""
        patches = []

        for img_info in tqdm(self.image_list, desc=f"Extracting {self.patch_size}x{self.patch_size} patches"):
            try:
                img_path = img_info['path']
                img = Image.open(img_path).convert('RGB')
                img_array = np.array(img)

                # 1024x1024ë¡œ ë¦¬ì‚¬ì´ì¦ˆ (ë…¼ë¬¸ê³¼ ë™ì¼)
                H, W = img_array.shape[:2]
                if H != 1024 or W != 1024:
                    img_array = cv2.resize(img_array, (1024, 1024))

                # íŒ¨ì¹˜ ì¶”ì¶œ
                patches_for_image = self._extract_patches_from_image(img_array)
                patches.extend(patches_for_image)

            except Exception as e:
                logger.warning(f"Failed to process {img_path}: {e}")
                continue

        logger.info(f"Generated {len(patches)} patches for {self.patch_size}x{self.patch_size}")
        return patches

    def _extract_patches_from_image(self, img_array):
        """ì´ë¯¸ì§€ì—ì„œ ê²©ì ê¸°ë°˜ íŒ¨ì¹˜ ì¶”ì¶œ"""
        H, W = img_array.shape[:2]
        patches = []

        # ë…¼ë¬¸ì˜ ê²©ì ë¶„í•  ë°©ì‹
        num_patches = 1024 // self.patch_size  # ê° ì°¨ì›ì˜ íŒ¨ì¹˜ ìˆ˜

        for i in range(num_patches):
            for j in range(num_patches):
                y = i * self.patch_size
                x = j * self.patch_size

                patch = img_array[y:y+self.patch_size, x:x+self.patch_size]
                if patch.shape[:2] == (self.patch_size, self.patch_size):
                    patches.append((patch, (x, y)))

        return patches

    def __len__(self):
        return len(self.patches)

    def __getitem__(self, idx):
        patch, position = self.patches[idx]

        try:
            # ê°™ì€ íŒ¨ì¹˜ì—ì„œ ë‘ ê°œì˜ augmented view ìƒì„±
            xi = self.transform(patch)
            xj = self.transform(patch)

            return xi, xj

        except Exception as e:
            logger.warning(f"Failed to process patch: {e}")
            return self.__getitem__((idx + 1) % len(self.patches))

# ===================================================================
# NT-Xent Loss í•¨ìˆ˜
# ===================================================================

class NTXentLoss(nn.Module):
    """NT-Xent ì†ì‹¤ í•¨ìˆ˜ (ë…¼ë¬¸ê³¼ ë™ì¼)"""
    def __init__(self, temperature=0.07):
        super(NTXentLoss, self).__init__()
        self.temperature = temperature

    def forward(self, zi, zj):
        batch_size = zi.shape[0]

        # L2 ì •ê·œí™”
        zi = F.normalize(zi, dim=-1)
        zj = F.normalize(zj, dim=-1)

        # Positive pairs: (zi, zj)
        representations = torch.cat([zi, zj], dim=0)

        # ìœ ì‚¬ë„ í–‰ë ¬ ê³„ì‚°
        similarity_matrix = F.cosine_similarity(
            representations.unsqueeze(1),
            representations.unsqueeze(0),
            dim=2
        )

        # ìê¸° ìì‹ ê³¼ì˜ ìœ ì‚¬ë„ ë§ˆìŠ¤í‚¹
        mask = torch.eye(2 * batch_size, dtype=torch.bool, device=zi.device)
        similarity_matrix = similarity_matrix.masked_fill(mask, -9e15)

        # ì˜¨ë„ ìŠ¤ì¼€ì¼ë§
        similarity_matrix = similarity_matrix / self.temperature

        # Positive indices
        positive_indices = torch.arange(batch_size, device=zi.device)
        positive_indices = torch.cat([positive_indices + batch_size, positive_indices])

        # Cross entropy loss
        loss = F.cross_entropy(similarity_matrix, positive_indices)

        return loss

# ===================================================================
# ë…¼ë¬¸ ë°©ì‹ ë‹¨ì¼ í•´ìƒë„ ëª¨ë¸ í•™ìŠµ
# ===================================================================

def train_single_resolution_model_paper_way(normal_images, patch_size, config):
    """ë…¼ë¬¸ ë°©ì‹ ë‹¨ì¼ í•´ìƒë„ ëª¨ë¸ í•™ìŠµ (ë°°ì¹˜ ì¶•ì  ì ìš©)"""
    logger.info(f"ğŸš€ Training model for {patch_size}x{patch_size} patches (Paper way)")

    # ëª¨ë¸ ì´ˆê¸°í™”
    model = SingleResolutionSwinSimCLR(
        patch_size=patch_size,
        feature_dim=config.feature_dim,
        projection_dim=config.projection_dim
    ).to(config.device)

    # ë°°ì¹˜ ì„¤ì • ê°€ì ¸ì˜¤ê¸°
    batch_config = config.batch_configs[patch_size]
    batch_size = batch_config['batch_size']
    accumulation_steps = batch_config['accumulation_steps']

    logger.info(f"Batch size: {batch_size}, Accumulation steps: {accumulation_steps}")

    # ë°ì´í„°ì…‹ ë° ë°ì´í„°ë¡œë”
    dataset = SingleResolutionDataset(normal_images, patch_size, config, is_training=True)
    dataloader = DataLoader(
        dataset,
        batch_size=batch_size,
        shuffle=True,
        num_workers=config.num_workers,
        pin_memory=True,
        drop_last=True
    )

    # ì˜µí‹°ë§ˆì´ì € ë° ìŠ¤ì¼€ì¤„ëŸ¬
    optimizer = optim.AdamW(
        model.parameters(),
        lr=config.learning_rate,
        weight_decay=config.weight_decay,
        betas=(0.9, 0.999)
    )

    scheduler = optim.lr_scheduler.CosineAnnealingLR(
        optimizer,
        T_max=config.epochs,
        eta_min=config.learning_rate * 0.01
    )

    # ì†ì‹¤ í•¨ìˆ˜
    criterion = NTXentLoss(temperature=config.temperature)

    # í•™ìŠµ ë£¨í”„
    train_losses = []

    for epoch in range(config.epochs):
        model.train()
        epoch_loss = 0
        batch_count = 0

        pbar = tqdm(dataloader, desc=f"Epoch {epoch+1}/{config.epochs}")

        optimizer.zero_grad()  # ì¶•ì  ì‹œì‘ ì „ ì´ˆê¸°í™”

        for batch_idx, (xi, xj) in enumerate(pbar):
            # ë°°ì¹˜ í¬ê¸° ì²´í¬
            if xi.size(0) <= 1:
                continue

            xi, xj = xi.to(config.device), xj.to(config.device)

            # Forward pass
            zi = model(xi)
            zj = model(xj)

            # Loss ê³„ì‚° (ì¶•ì ì„ ìœ„í•´ í‰ê· í™”)
            loss = criterion(zi, zj) / accumulation_steps

            # Backward pass
            loss.backward()

            # ë°°ì¹˜ ì¶•ì 
            if (batch_idx + 1) % accumulation_steps == 0:
                torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)
                optimizer.step()
                optimizer.zero_grad()

            epoch_loss += loss.item() * accumulation_steps  # ì‹¤ì œ ì†ì‹¤ë¡œ ë³µì›
            batch_count += 1

            pbar.set_postfix({
                'Loss': f'{loss.item() * accumulation_steps:.4f}',
                'Avg': f'{epoch_loss/batch_count:.4f}',
                'LR': f'{optimizer.param_groups[0]["lr"]:.2e}'
            })

        # ë§ˆì§€ë§‰ ë°°ì¹˜ ì²˜ë¦¬
        if batch_count % accumulation_steps != 0:
            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)
            optimizer.step()

        scheduler.step()
        avg_loss = epoch_loss / max(batch_count, 1)
        train_losses.append(avg_loss)

        logger.info(f"Patch {patch_size}x{patch_size} - Epoch {epoch+1}: Loss = {avg_loss:.4f}")

        # ì¡°ê¸° ì¢…ë£Œ ì¡°ê±´
        if len(train_losses) > 10:
            recent_losses = train_losses[-10:]
            if max(recent_losses) - min(recent_losses) < 0.01:
                logger.info(f"Early stopping for {patch_size}x{patch_size} at epoch {epoch+1}")
                break

    return model, train_losses

# ===================================================================
# ë…¼ë¬¸ ë°©ì‹ ì°¸ì¡° ë°ì´í„°ë² ì´ìŠ¤
# ===================================================================

class PaperBasedReferenceDB:
    """ë…¼ë¬¸ ë°©ì‹ ì°¸ì¡° ë°ì´í„°ë² ì´ìŠ¤ (Mahalanobis ê±°ë¦¬ ê³„ì‚°ìš©)"""

    def __init__(self, patch_sizes):
        self.patch_sizes = patch_sizes
        self.features_db = {size: [] for size in patch_sizes}
        self.positions_db = {size: [] for size in patch_sizes}
        self.covariance_matrices = {}
        self.mean_features = {}

    def build_reference_database(self, model_manager, normal_images, config):
        """ê° í•´ìƒë„ë³„ ì°¸ì¡° DB êµ¬ì¶• (ë…¼ë¬¸ ë°©ì‹)"""
        logger.info("ğŸ” Building reference database (Paper way - Mahalanobis)...")

        for patch_size in self.patch_sizes:
            logger.info(f"Processing {patch_size}x{patch_size} features...")

            model = model_manager.models[patch_size]
            model.eval()

            # í•´ë‹¹ í•´ìƒë„ ë°ì´í„°ì…‹ (ì¶”ë¡ ìš©)
            dataset = SingleResolutionDataset(
                normal_images[:150], patch_size, config, is_training=False  # ë” ì ì€ ì´ë¯¸ì§€ë¡œ ë¹ ë¥¸ ì²˜ë¦¬
            )

            features_list = []
            positions_list = []

            # ë°°ì¹˜ ë‹¨ìœ„ë¡œ íŠ¹ì§• ì¶”ì¶œ
            batch_size = 16
            batch_patches = []
            batch_positions = []

            with torch.no_grad():
                for i in range(len(dataset)):
                    xi, _ = dataset[i]  # ì¶”ë¡ ì‹œì—ëŠ” xië§Œ ì‚¬ìš©
                    patch, position = dataset.patches[i]

                    batch_patches.append(xi)
                    batch_positions.append(position)

                    # ë°°ì¹˜ê°€ ì°¨ë©´ ì²˜ë¦¬
                    if len(batch_patches) >= batch_size:
                        batch_tensor = torch.stack(batch_patches).to(config.device)
                        features = model.get_features(batch_tensor)
                        features_np = features.cpu().numpy()

                        features_list.extend(features_np)
                        positions_list.extend(batch_positions)

                        # ë°°ì¹˜ ì´ˆê¸°í™”
                        batch_patches = []
                        batch_positions = []

                # ë‚¨ì€ ë°°ì¹˜ ì²˜ë¦¬
                if batch_patches:
                    batch_tensor = torch.stack(batch_patches).to(config.device)
                    features = model.get_features(batch_tensor)
                    features_np = features.cpu().numpy()

                    features_list.extend(features_np)
                    positions_list.extend(batch_positions)

            # ë°ì´í„°ë² ì´ìŠ¤ì— ì¶”ê°€
            if features_list:
                self.features_db[patch_size] = features_list
                self.positions_db[patch_size] = positions_list

                # Mahalanobis ê±°ë¦¬ë¥¼ ìœ„í•œ í‰ê· ê³¼ ê³µë¶„ì‚° ê³„ì‚°
                features_array = np.array(features_list)
                self.mean_features[patch_size] = np.mean(features_array, axis=0)

                # ê³µë¶„ì‚° í–‰ë ¬ ê³„ì‚° (ì •ê·œí™” ì ìš©)
                cov_estimator = EmpiricalCovariance()
                cov_estimator.fit(features_array)
                self.covariance_matrices[patch_size] = cov_estimator.covariance_

                logger.info(f"Added {len(features_list)} features for {patch_size}x{patch_size}")
                logger.info(f"Mean shape: {self.mean_features[patch_size].shape}")
                logger.info(f"Covariance shape: {self.covariance_matrices[patch_size].shape}")

        # ì°¸ì¡° DB ì €ì¥
        self._save_reference_db(config.save_dir)

    def _save_reference_db(self, save_dir):
        """ì°¸ì¡° DB ì €ì¥"""
        os.makedirs(save_dir, exist_ok=True)

        for patch_size in self.patch_sizes:
            # ê° í•´ìƒë„ë³„ ë°ì´í„° ì €ì¥
            ref_data = {
                'features': self.features_db[patch_size],
                'positions': self.positions_db[patch_size],
                'mean_features': self.mean_features.get(patch_size),
                'covariance_matrix': self.covariance_matrices.get(patch_size),
                'patch_size': patch_size
            }

            ref_db_path = os.path.join(save_dir, f'paper_reference_db_{patch_size}px.pkl')
            with open(ref_db_path, 'wb') as f:
                pickle.dump(ref_data, f)

            logger.info(f"ğŸ’¾ Saved {patch_size}px reference DB: {ref_db_path}")

    def load_reference_db(self, save_dir):
        """ì°¸ì¡° DB ë¡œë“œ"""
        for patch_size in self.patch_sizes:
            ref_db_path = os.path.join(save_dir, f'paper_reference_db_{patch_size}px.pkl')

            if os.path.exists(ref_db_path):
                with open(ref_db_path, 'rb') as f:
                    data = pickle.load(f)

                self.features_db[patch_size] = data['features']
                self.positions_db[patch_size] = data['positions']
                self.mean_features[patch_size] = data['mean_features']
                self.covariance_matrices[patch_size] = data['covariance_matrix']

                logger.info(f"âœ… Loaded {patch_size}px reference DB")
            else:
                logger.warning(f"Reference DB not found: {ref_db_path}")

# ===================================================================
# ë©€í‹°í•´ìƒë„ ëª¨ë¸ ê´€ë¦¬ì
# ===================================================================

class MultiResolutionModelManager:
    """ë©€í‹°í•´ìƒë„ ëª¨ë¸ ê´€ë¦¬ì (ë…¼ë¬¸ ë°©ì‹)"""

    def __init__(self, config):
        self.config = config
        self.models = {}
        self.training_histories = {}

    def train_all_resolutions(self, normal_images):
        """ëª¨ë“  í•´ìƒë„ ëª¨ë¸ ìˆœì°¨ í•™ìŠµ (ë…¼ë¬¸ ë°©ì‹)"""
        logger.info("ğŸš€ Starting multi-resolution training (Paper way)")

        for patch_size in self.config.patch_sizes:
            logger.info(f"\n{'='*60}")
            logger.info(f"ğŸ“Š Training Resolution: {patch_size}x{patch_size}")
            logger.info(f"ğŸ“Š Batch Config: {self.config.batch_configs[patch_size]}")
            logger.info(f"{'='*60}")

            # í•´ë‹¹ í•´ìƒë„ ëª¨ë¸ í•™ìŠµ
            model, losses = train_single_resolution_model_paper_way(
                normal_images, patch_size, self.config
            )

            # ì €ì¥
            self.models[patch_size] = model
            self.training_histories[patch_size] = losses

            # ì²´í¬í¬ì¸íŠ¸ ì €ì¥
            self._save_checkpoint(patch_size, model, losses)

        logger.info("\nâœ… All resolution models trained successfully!")

    def _save_checkpoint(self, patch_size, model, losses):
        """í•´ìƒë„ë³„ ì²´í¬í¬ì¸íŠ¸ ì €ì¥"""
        os.makedirs(self.config.save_dir, exist_ok=True)

        checkpoint_path = os.path.join(
            self.config.save_dir,
            f'paper_model_{patch_size}x{patch_size}.pth'
        )

        torch.save({
            'model_state_dict': model.state_dict(),
            'patch_size': patch_size,
            'training_losses': losses,
            'config': self.config.__dict__,
            'timestamp': datetime.now().isoformat()
        }, checkpoint_path)

        logger.info(f"ğŸ’¾ Saved model for {patch_size}x{patch_size}: {checkpoint_path}")

    def load_models(self, checkpoint_dir=None):
        """ì €ì¥ëœ ëª¨ë¸ë“¤ ë¡œë“œ"""
        if checkpoint_dir is None:
            checkpoint_dir = self.config.save_dir

        for patch_size in self.config.patch_sizes:
            checkpoint_path = os.path.join(
                checkpoint_dir,
                f'paper_model_{patch_size}x{patch_size}.pth'
            )

            if os.path.exists(checkpoint_path):
                checkpoint = torch.load(checkpoint_path)

                model = SingleResolutionSwinSimCLR(
                    patch_size=patch_size,
                    feature_dim=self.config.feature_dim,
                    projection_dim=self.config.projection_dim
                ).to(self.config.device)

                model.load_state_dict(checkpoint['model_state_dict'])
                self.models[patch_size] = model
                self.training_histories[patch_size] = checkpoint['training_losses']

                logger.info(f"âœ… Loaded model for {patch_size}x{patch_size}")

# ===================================================================
# ë…¼ë¬¸ ë°©ì‹ ì´ìƒì ìˆ˜ ê³„ì‚°
# ===================================================================

def compute_patch_anomaly_score_paper_way(query_features, position, patch_size, reference_db, config):
    """ë…¼ë¬¸ ë°©ì‹ íŒ¨ì¹˜ ì´ìƒì ìˆ˜ ê³„ì‚° (Mahalanobis + locality)"""

    if patch_size not in reference_db.features_db:
        return 0.5

    # ë…¼ë¬¸ì˜ patch distance íŒŒë¼ë¯¸í„°
    patch_distance = config.patch_distance_params[patch_size]

    # ì°¸ì¡° íŠ¹ì§•ë“¤ê³¼ ìœ„ì¹˜ë“¤
    ref_features = np.array(reference_db.features_db[patch_size])
    ref_positions = reference_db.positions_db[patch_size]

    # Locality ê³ ë ¤í•œ ì°¸ì¡° íŠ¹ì§• í•„í„°ë§
    if patch_distance > 0:
        valid_indices = []
        for i, ref_pos in enumerate(ref_positions):
            distance = np.sqrt((position[0] - ref_pos[0])**2 + (position[1] - ref_pos[1])**2)
            if distance <= patch_distance * patch_size:
                valid_indices.append(i)

        if valid_indices:
            ref_features = ref_features[valid_indices]
        else:
            # ì§€ì—­ ì°¸ì¡°ê°€ ì—†ìœ¼ë©´ ì „ì—­ ì‚¬ìš©
            pass

    # Mahalanobis ê±°ë¦¬ ê³„ì‚°
    try:
        mean_feat = reference_db.mean_features[patch_size]
        cov_matrix = reference_db.covariance_matrices[patch_size]

        # ê° ì°¸ì¡° íŠ¹ì§•ê³¼ì˜ Mahalanobis ê±°ë¦¬ ê³„ì‚°
        min_distance = float('inf')

        for ref_feat in ref_features:
            diff = query_features - ref_feat
            # Mahalanobis ê±°ë¦¬ = sqrt((x-y)^T * Î£^-1 * (x-y))
            try:
                inv_cov = np.linalg.inv(cov_matrix + np.eye(cov_matrix.shape[0]) * 1e-6)  # ìˆ˜ì¹˜ ì•ˆì •ì„±
                distance = np.sqrt(np.dot(np.dot(diff, inv_cov), diff))
                min_distance = min(min_distance, distance)
            except:
                # ì—­í–‰ë ¬ ê³„ì‚° ì‹¤íŒ¨ì‹œ ìœ í´ë¦¬ë“œ ê±°ë¦¬ ì‚¬ìš©
                distance = np.linalg.norm(diff)
                min_distance = min(min_distance, distance)

        # ê±°ë¦¬ë¥¼ [0,1] ë²”ìœ„ë¡œ ì •ê·œí™” (ë…¼ë¬¸ì˜ similarityë¥¼ anomaly scoreë¡œ ë³€í™˜)
        anomaly_score = min(1.0, min_distance / 10.0)  # ê²½í—˜ì  ìŠ¤ì¼€ì¼ë§

    except Exception as e:
        logger.warning(f"Mahalanobis calculation failed: {e}")
        # í´ë°±: ìœ í´ë¦¬ë“œ ê±°ë¦¬
        min_distance = float('inf')
        for ref_feat in ref_features:
            distance = np.linalg.norm(query_features - ref_feat)
            min_distance = min(min_distance, distance)
        anomaly_score = min(1.0, min_distance / 1000.0)  # ê²½í—˜ì  ìŠ¤ì¼€ì¼ë§

    return float(anomaly_score)

def compute_multiresolution_anomaly_score_paper_way(img_array, model_manager, reference_db, config):
    """ë…¼ë¬¸ ë°©ì‹ ë©€í‹°í•´ìƒë„ ì´ìƒì ìˆ˜ ê³„ì‚°"""
    resolution_scores = {}

    for patch_size in config.patch_sizes:
        model = model_manager.models[patch_size]
        model.eval()

        # ë…¼ë¬¸ ë°©ì‹ íŒ¨ì¹˜ ì¶”ì¶œ (ê²©ì)
        patches = extract_patches_paper_way(img_array, patch_size)

        patch_scores = []

        with torch.no_grad():
            for patch, position in patches:
                # íŒ¨ì¹˜ ì „ì²˜ë¦¬
                transform = transforms.Compose([
                    transforms.ToPILImage(),
                    transforms.Resize((patch_size, patch_size)),
                    transforms.ToTensor(),
                    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
                ])

                patch_tensor = transform(patch).unsqueeze(0).to(config.device)

                # íŠ¹ì§• ì¶”ì¶œ
                features = model.get_features(patch_tensor)
                features_np = features.cpu().numpy().flatten()

                # ë…¼ë¬¸ ë°©ì‹ ì´ìƒì ìˆ˜ ê³„ì‚°
                anomaly_score = compute_patch_anomaly_score_paper_way(
                    features_np, position, patch_size, reference_db, config
                )

                patch_scores.append(anomaly_score)

        # í•´ìƒë„ë³„ ìµœëŒ€ ì´ìƒì ìˆ˜ (ë…¼ë¬¸ ë°©ì‹)
        if patch_scores:
            resolution_scores[patch_size] = max(patch_scores)
        else:
            resolution_scores[patch_size] = 0.0

    # ë…¼ë¬¸ì˜ ê°€ì¤‘ì¹˜ ê¸°ë°˜ ìœµí•©
    weighted_score = 0.0
    total_weight = 0.0

    for patch_size, weight in config.resolution_weights.items():
        if patch_size in resolution_scores:
            weighted_score += weight * resolution_scores[patch_size]
            total_weight += weight

    final_score = weighted_score / total_weight if total_weight > 0 else 0.0

    return final_score

def extract_patches_paper_way(img_array, patch_size):
    """ë…¼ë¬¸ ë°©ì‹ íŒ¨ì¹˜ ì¶”ì¶œ (ê²©ì ê¸°ë°˜)"""
    H, W = img_array.shape[:2]
    patches = []

    # ë…¼ë¬¸ì˜ ê²©ì ë¶„í•  ë°©ì‹
    num_patches = 1024 // patch_size  # ê° ì°¨ì›ì˜ íŒ¨ì¹˜ ìˆ˜

    for i in range(num_patches):
        for j in range(num_patches):
            y = i * patch_size
            x = j * patch_size

            patch = img_array[y:y+patch_size, x:x+patch_size]
            if patch.shape[:2] == (patch_size, patch_size):
                patches.append((patch, (x, y)))

    return patches

# ===================================================================
# ì‹¤ì œ ë°ì´í„° ë¡œë”
# ===================================================================

class RealDataProcessor:
    """ì‹¤ì œ í‰ë¶€ X-ray ë°ì´í„° ì²˜ë¦¬ê¸°"""

    def __init__(self, config):
        self.config = config
        self.normal_images = []
        self.abnormal_images = []

    def load_nih_dataset(self):
        """NIH Chest X-ray ë°ì´í„°ì…‹ ë¡œë“œ"""
        logger.info("Loading NIH Chest X-ray dataset...")

        # CSV íŒŒì¼ ì½ê¸°
        if not os.path.exists(self.config.csv_path):
            logger.error(f"CSV file not found: {self.config.csv_path}")
            raise FileNotFoundError(f"Please check the path: {self.config.csv_path}")

        df = pd.read_csv(self.config.csv_path)
        logger.info(f"Loaded CSV with {len(df)} entries")

        # ì •ìƒ ì´ë¯¸ì§€ (No Finding)
        normal_df = df[df['Finding Labels'] == 'No Finding']
        logger.info(f"Found {len(normal_df)} normal images")

        # ì´ìƒ ì´ë¯¸ì§€ (No Findingì´ ì•„ë‹Œ ê²ƒë“¤)
        abnormal_df = df[df['Finding Labels'] != 'No Finding']
        logger.info(f"Found {len(abnormal_df)} abnormal images")

        # ì •ìƒ ì´ë¯¸ì§€ ì²˜ë¦¬
        normal_sample = normal_df.sample(n=min(self.config.max_normal_images * 2, len(normal_df)),
                                       random_state=42)
        self.normal_images = self._validate_images(normal_sample, 'normal', self.config.max_normal_images)

        # ì´ìƒ ì´ë¯¸ì§€ ì²˜ë¦¬
        abnormal_sample = abnormal_df.sample(n=min(self.config.max_abnormal_images * 2, len(abnormal_df)),
                                           random_state=42)
        self.abnormal_images = self._validate_images(abnormal_sample, 'abnormal', self.config.max_abnormal_images)

        logger.info(f"âœ… Final dataset: {len(self.normal_images)} normal, {len(self.abnormal_images)} abnormal")

        return self.normal_images, self.abnormal_images

    def _validate_images(self, df, image_type, max_count):
        """ì´ë¯¸ì§€ íŒŒì¼ ê²€ì¦ ë° ê²½ë¡œ êµ¬ì„±"""
        valid_images = []

        for _, row in tqdm(df.iterrows(), desc=f"Validating {image_type} images", total=len(df)):
            if len(valid_images) >= max_count:
                break

            image_name = row['Image Index']
            image_path = self._find_image_path(image_name)

            if image_path and self._is_valid_image(image_path):
                valid_images.append({
                    'path': image_path,
                    'image_name': image_name,
                    'patient_id': row.get('Patient ID', 'unknown'),
                    'finding_labels': row.get('Finding Labels', ''),
                    'follow_up': row.get('Follow-up #', 0),
                    'patient_age': row.get('Patient Age', 0),
                    'patient_gender': row.get('Patient Gender', 'unknown'),
                    'view_position': row.get('View Position', 'unknown')
                })

        return valid_images

    def _find_image_path(self, image_name):
        """ì´ë¯¸ì§€ íŒŒì¼ ê²½ë¡œ ì°¾ê¸° (NIH ë°ì´í„°ì…‹ì€ ì—¬ëŸ¬ í´ë”ë¡œ ë¶„ì‚°)"""
        # NIH ë°ì´í„°ì…‹ì€ images_001, images_002, ... images_012 í´ë”ë¡œ êµ¬ì„±
        for i in range(1, 13):
            folder_name = f"images_{i:03d}"
            folder_path = os.path.join(self.config.image_base_path, folder_name, "images")
            image_path = os.path.join(folder_path, image_name)

            if os.path.exists(image_path):
                return image_path

        return None

    def _is_valid_image(self, image_path):
        """ì´ë¯¸ì§€ íŒŒì¼ ìœ íš¨ì„± ê²€ì‚¬"""
        try:
            img = Image.open(image_path)
            img.verify()  # ì´ë¯¸ì§€ ë¬´ê²°ì„± ê²€ì‚¬

            # ìµœì†Œ í¬ê¸° ê²€ì‚¬
            img = Image.open(image_path)  # verify() í›„ ë‹¤ì‹œ ì—´ì–´ì•¼ í•¨
            width, height = img.size
            if width < 512 or height < 512:
                return False

            return True
        except Exception:
            return False

# ===================================================================
# í‰ê°€ í•¨ìˆ˜
# ===================================================================

def evaluate_paper_method(normal_images, abnormal_images, config):
    """ë…¼ë¬¸ ë°©ì‹ í‰ê°€ (ë‹¨ìˆœ train/test split)"""
    logger.info("ğŸ” Starting Paper Method Evaluation")

    # 80/20 ë¶„í•  (ë…¼ë¬¸ê³¼ ìœ ì‚¬)
    train_split = int(0.8 * len(normal_images))
    train_normal = normal_images[:train_split]
    test_normal = normal_images[train_split:]

    # í…ŒìŠ¤íŠ¸ìš© (ì •ìƒ + ì´ìƒ)
    test_images = test_normal + abnormal_images
    test_labels = [0] * len(test_normal) + [1] * len(abnormal_images)

    logger.info(f"Train (normal only): {len(train_normal)}")
    logger.info(f"Test: {len(test_images)} (Normal: {len(test_normal)}, Abnormal: {len(abnormal_images)})")

    # ëª¨ë¸ ê´€ë¦¬ì ì´ˆê¸°í™”
    model_manager = MultiResolutionModelManager(config)

    # ì •ìƒì´ë¯¸ì§€ë¡œë§Œ ëª¨ë“  í•´ìƒë„ ëª¨ë¸ í•™ìŠµ (ë…¼ë¬¸ ë°©ì‹)
    model_manager.train_all_resolutions(train_normal)

    # ì •ìƒì´ë¯¸ì§€ë¡œë§Œ ì°¸ì¡° ë°ì´í„°ë² ì´ìŠ¤ êµ¬ì¶• (ë…¼ë¬¸ ë°©ì‹)
    reference_db = PaperBasedReferenceDB(config.patch_sizes)
    reference_db.build_reference_database(model_manager, train_normal, config)

    # í…ŒìŠ¤íŠ¸ í‰ê°€
    predictions = []
    anomaly_scores = []

    for i, img_info in enumerate(tqdm(test_images, desc="Testing images")):
        try:
            # ì´ë¯¸ì§€ ë¡œë“œ
            img_path = img_info['path'] if isinstance(img_info, dict) else img_info
            img = Image.open(img_path).convert('RGB')
            img_array = np.array(img)

            if img_array.shape[:2] != (1024, 1024):
                img_array = cv2.resize(img_array, (1024, 1024))

            # ë…¼ë¬¸ ë°©ì‹ ë©€í‹°í•´ìƒë„ ì´ìƒì ìˆ˜ ê³„ì‚°
            overall_score = compute_multiresolution_anomaly_score_paper_way(
                img_array, model_manager, reference_db, config
            )

            anomaly_scores.append(overall_score)
            predictions.append(1 if overall_score > config.anomaly_threshold else 0)

        except Exception as e:
            logger.warning(f"Failed to process test image {i}: {e}")
            anomaly_scores.append(0.0)
            predictions.append(0)

    # ì„±ëŠ¥ ë©”íŠ¸ë¦­ ê³„ì‚°
    accuracy = accuracy_score(test_labels, predictions)
    precision = precision_score(test_labels, predictions, zero_division=0)
    recall = recall_score(test_labels, predictions, zero_division=0)
    specificity = recall_score([1-x for x in test_labels], [1-x for x in predictions], zero_division=0)

    try:
        auroc = roc_auc_score(test_labels, anomaly_scores)
    except:
        auroc = 0.0

    cm = confusion_matrix(test_labels, predictions)

    results = {
        'accuracy': float(accuracy),
        'precision': float(precision),
        'sensitivity': float(recall),
        'specificity': float(specificity),
        'auroc': float(auroc),
        'confusion_matrix': cm.tolist(),
        'predictions': predictions,
        'anomaly_scores': anomaly_scores,
        'test_labels': test_labels,
        'method': 'paper_based_multiresolution'
    }

    logger.info(f"Paper Method Results:")
    logger.info(f"  Accuracy: {accuracy:.3f}")
    logger.info(f"  Precision: {precision:.3f}")
    logger.info(f"  Sensitivity: {recall:.3f}")
    logger.info(f"  Specificity: {specificity:.3f}")
    logger.info(f"  AUROC: {auroc:.3f}")

    # ê²°ê³¼ ì €ì¥
    results_path = os.path.join(config.save_dir, 'paper_method_results.json')
    with open(results_path, 'w') as f:
        json.dump(results, f, indent=2)

    # ì²´í¬í¬ì¸íŠ¸ì™€ ì°¸ì¡° DB ì €ì¥
    model_manager._save_all_checkpoints()
    reference_db._save_reference_db(config.save_dir)

    return results

# ===================================================================
# ì‹œê°í™” í•¨ìˆ˜
# ===================================================================

def plot_paper_results(results, config):
    """ë…¼ë¬¸ ë°©ì‹ ê²°ê³¼ ì‹œê°í™”"""
    fig, axes = plt.subplots(1, 3, figsize=(15, 5))
    fig.suptitle('Paper-based Multi-resolution CXR Anomaly Detection Results', fontsize=14, fontweight='bold')

    # 1. ì„±ëŠ¥ ë©”íŠ¸ë¦­ ë°” ì°¨íŠ¸
    metrics = ['accuracy', 'precision', 'sensitivity', 'specificity', 'auroc']
    values = [results[metric] for metric in metrics]

    axes[0].bar(range(len(metrics)), values, color=['skyblue', 'lightgreen', 'orange', 'pink', 'lightcoral'])
    axes[0].set_xticks(range(len(metrics)))
    axes[0].set_xticklabels([m.capitalize() for m in metrics], rotation=45)
    axes[0].set_ylabel('Score')
    axes[0].set_title('Performance Metrics')
    axes[0].set_ylim(0, 1)

    # ê°’ í‘œì‹œ
    for i, v in enumerate(values):
        axes[0].text(i, v + 0.01, f'{v:.3f}', ha='center', va='bottom')

    # 2. í˜¼ë™í–‰ë ¬
    cm = np.array(results['confusion_matrix'])
    im = axes[1].imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)
    axes[1].set_title('Confusion Matrix')

    # í˜¼ë™í–‰ë ¬ í…ìŠ¤íŠ¸ ì¶”ê°€
    thresh = cm.max() / 2.
    for i in range(cm.shape[0]):
        for j in range(cm.shape[1]):
            axes[1].text(j, i, format(cm[i, j], 'd'),
                       ha="center", va="center",
                       color="white" if cm[i, j] > thresh else "black",
                       fontweight='bold')

    axes[1].set_ylabel('True Label')
    axes[1].set_xlabel('Predicted Label')
    axes[1].set_xticks([0, 1])
    axes[1].set_xticklabels(['Normal', 'Abnormal'])
    axes[1].set_yticks([0, 1])
    axes[1].set_yticklabels(['Normal', 'Abnormal'])

    # 3. ROC ê³¡ì„ 
    try:
        fpr, tpr, _ = roc_curve(results['test_labels'], results['anomaly_scores'])
        axes[2].plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {results["auroc"]:.3f})')
        axes[2].plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--', label='Random')
        axes[2].set_xlim([0.0, 1.0])
        axes[2].set_ylim([0.0, 1.05])
        axes[2].set_xlabel('False Positive Rate')
        axes[2].set_ylabel('True Positive Rate')
        axes[2].set_title('ROC Curve')
        axes[2].legend(loc="lower right")
        axes[2].grid(True, alpha=0.3)
    except:
        axes[2].text(0.5, 0.5, 'ROC Curve\nNot Available', ha='center', va='center', transform=axes[2].transAxes)

    plt.tight_layout()

    # ì €ì¥
    save_path = os.path.join(config.save_dir, 'paper_method_visualization.png')
    plt.savefig(save_path, dpi=300, bbox_inches='tight', facecolor='white')
    plt.close()

    logger.info(f"ğŸ“Š Paper method visualization saved: {save_path}")

# ===================================================================
# ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜
# ===================================================================

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("="*80)
    print("ğŸš€ PAPER-BASED MULTI-RESOLUTION CXR ANOMALY DETECTION")
    print("   Original Paper Implementation")
    print("="*80)
    print(f"ğŸ“… Started at: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print("ğŸ”§ Key Features:")
    print("â€¢ Paper-based patch extraction (grid)")
    print("â€¢ Mahalanobis distance calculation (no FAISS)")
    print("â€¢ Batch accumulation training (128,256: 4 batch, 512,1024: 2 batch)")
    print("â€¢ Paper's patch distance parameters")
    print("â€¢ Normal images ONLY training")
    print("â€¢ Multi-resolution weight fusion")
    print("â€¢ Real NIH Chest X-ray Dataset")
    print("="*80)

    try:
        # ê²°ê³¼ ë””ë ‰í† ë¦¬ ìƒì„±
        os.makedirs(config.save_dir, exist_ok=True)

        # 1. ì‹¤ì œ ë°ì´í„° ë¡œë“œ
        print("\nğŸ”„ STEP 1: Loading real NIH Chest X-ray dataset...")
        data_processor = RealDataProcessor(config)
        normal_images, abnormal_images = data_processor.load_nih_dataset()

        if len(normal_images) == 0 or len(abnormal_images) == 0:
            raise ValueError("Failed to load sufficient data. Please check data paths.")

        # 2. ë…¼ë¬¸ ë°©ì‹ í‰ê°€
        print("\nğŸ“Š STEP 2: Paper-based evaluation...")
        results = evaluate_paper_method(normal_images, abnormal_images, config)

        # 3. ê²°ê³¼ ì‹œê°í™”
        print("\nğŸ“ˆ STEP 3: Creating visualizations...")
        plot_paper_results(results, config)

        # 4. ìµœì¢… ê²°ê³¼ ì¶œë ¥
        print("\n" + "="*80)
        print("ğŸ‰ PAPER-BASED EVALUATION COMPLETED!")
        print("="*80)

        print(f"\nğŸ“Š FINAL PERFORMANCE SUMMARY:")
        for metric in ['accuracy', 'precision', 'sensitivity', 'specificity', 'auroc']:
            value = results[metric]
            print(f"   ğŸ¯ {metric.capitalize()}: {value:.3f}")

        print(f"\nğŸ“ Generated Files:")
        print(f"   â€¢ Results: {config.save_dir}/paper_method_results.json")
        print(f"   â€¢ Visualization: {config.save_dir}/paper_method_visualization.png")
        print(f"   â€¢ Models: {config.save_dir}/paper_model_{{128,256,512,1024}}x{{128,256,512,1024}}.pth")
        print(f"   â€¢ Reference DBs: {config.save_dir}/paper_reference_db_{{128,256,512,1024}}px.pkl")

        print(f"\nğŸ’¡ Paper-based Features:")
        print(f"   â€¢ Patch Sizes: {config.patch_sizes}")
        print(f"   â€¢ Resolution Weights: {config.resolution_weights}")
        print(f"   â€¢ Patch Distance Params: {config.patch_distance_params}")
        print(f"   â€¢ Batch Configs: {config.batch_configs}")
        print(f"   â€¢ Grid-based patch extraction âœ“")
        print(f"   â€¢ Mahalanobis distance calculation âœ“")
        print(f"   â€¢ Batch accumulation training âœ“")
        print(f"   â€¢ Normal images only training âœ“")
        print(f"   â€¢ Multi-resolution fusion âœ“")

        return results

    except Exception as e:
        print(f"\nâŒ Evaluation failed: {str(e)}")
        import traceback
        traceback.print_exc()
        return None

if __name__ == "__main__":
    # ì‹¤í–‰
    results = main()

    if results:
        print("\nğŸ‰ SUCCESS: Paper-based multi-resolution evaluation completed!")
        print("   â€¢ Exact paper implementation")
        print("   â€¢ Mahalanobis distance without FAISS")
        print("   â€¢ Batch accumulation for efficient training")
        print("   â€¢ Grid-based patch extraction")
        print("   â€¢ Normal images ONLY training (unsupervised learning)")
        print("   â€¢ Multi-resolution weight fusion")
        print("   â€¢ Patch locality consideration")
        print("   â€¢ Ready for CDSS integration!")
    else:
        print("\nâŒ Evaluation failed. Please check the error messages.")
        print("\nğŸ”§ Common Solutions:")
        print("â€¢ Verify NIH dataset is properly downloaded")
        print("â€¢ Check data paths in config")
        print("â€¢ Ensure sufficient normal images for training")
        print("â€¢ Ensure all dependencies are installed")

    print("\nğŸ Paper-based Multi-Resolution CXR Anomaly Detection System Ready!")
    print("ğŸ’¡ Perfect for CDSS integration with OpenMRS and ORTHANC-PACS")
    print("ğŸ“‹ Implementation: Exact paper methodology")
    print("ğŸ« Evaluation Strategy: Simple train/test split")
    print("ğŸ’¾ Storage Strategy: Resolution-specific models and Mahalanobis DBs")