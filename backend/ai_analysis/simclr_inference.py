import torch
import torch.nn as nn
import torch.nn.functional as F
import numpy as np
import cv2
from PIL import Image
import io
import requests
import pickle
import os
import matplotlib.pyplot as plt
import matplotlib.patches as patches
from datetime import datetime
import logging
from django.conf import settings
from sklearn.covariance import EmpiricalCovariance

# SwimSimCLR Î™®Îç∏ import (Í∏∞Ï°¥ ÏΩîÎìú Ïû¨ÏÇ¨Ïö©)
from .swinsimclr_models import (
    SingleResolutionSwinSimCLR, 
    PaperBasedConfig,
    extract_patches_paper_way,
    compute_patch_anomaly_score_paper_way
)

logger = logging.getLogger(__name__)

class SimCLRInferenceService:
    """DjangoÏö© SimCLR Ï∂îÎ°† ÏÑúÎπÑÏä§"""
    
    def __init__(self):
        self.config = PaperBasedConfig()
        self.models = {}
        self.reference_db = {}
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        self.is_loaded = False
        
        # Django ÏÑ§Ï†ïÏóêÏÑú Í≤ΩÎ°ú Í∞ÄÏ†∏Ïò§Í∏∞
        self.weights_dir = getattr(settings, 'SIMCLR_WEIGHTS_DIR', './weights')
        self.reference_db_dir = getattr(settings, 'SIMCLR_REFERENCE_DB_DIR', './reference_db')
        self.results_dir = getattr(settings, 'SIMCLR_RESULTS_DIR', './media/simclr_results')
        
        # Í≤∞Í≥º ÎîîÎ†âÌÜ†Î¶¨ ÏÉùÏÑ±
        os.makedirs(self.results_dir, exist_ok=True)
    
    def load_models(self):
        """Î™®Îç∏Í≥º Ï∞∏Ï°∞ DB Î°úÎìú"""
        try:
            logger.info("üöÄ SimCLR Î™®Îç∏ Î°úÎî© ÏãúÏûë...")
            
            # Í∞Å Ìï¥ÏÉÅÎèÑÎ≥Ñ Î™®Îç∏ Î°úÎìú
            for patch_size in self.config.patch_sizes:
                model_path = os.path.join(self.weights_dir, f'simclr_model_{patch_size}px.pth')
                
                if os.path.exists(model_path):
                    model = SingleResolutionSwinSimCLR(
                        patch_size=patch_size,
                        feature_dim=self.config.feature_dim,
                        projection_dim=self.config.projection_dim
                    ).to(self.device)
                    
                    checkpoint = torch.load(model_path, map_location=self.device)
                    model.load_state_dict(checkpoint['model_state_dict'])
                    model.eval()
                    
                    self.models[patch_size] = model
                    logger.info(f"‚úÖ {patch_size}px Î™®Îç∏ Î°úÎìú ÏôÑÎ£å")
                else:
                    logger.warning(f"‚ö†Ô∏è {model_path} Î™®Îç∏ ÌååÏùºÏù¥ ÏóÜÏäµÎãàÎã§")
            
            # Ï∞∏Ï°∞ DB Î°úÎìú
            self.load_reference_database()
            
            self.is_loaded = True
            logger.info("‚úÖ SimCLR ÏÑúÎπÑÏä§ Ï¥àÍ∏∞Ìôî ÏôÑÎ£å")
            
        except Exception as e:
            logger.error(f"‚ùå Î™®Îç∏ Î°úÎî© Ïã§Ìå®: {e}")
            raise e
    
    def load_reference_database(self):
        """Ï∞∏Ï°∞ Îç∞Ïù¥ÌÑ∞Î≤†Ïù¥Ïä§ Î°úÎìú"""
        for patch_size in self.config.patch_sizes:
            ref_db_path = os.path.join(self.reference_db_dir, f'paper_reference_db_{patch_size}px.pkl')
            
            if os.path.exists(ref_db_path):
                with open(ref_db_path, 'rb') as f:
                    data = pickle.load(f)
                
                self.reference_db[patch_size] = data
                logger.info(f"‚úÖ {patch_size}px Ï∞∏Ï°∞ DB Î°úÎìú ÏôÑÎ£å")
            else:
                logger.warning(f"‚ö†Ô∏è {ref_db_path} Ï∞∏Ï°∞ DBÍ∞Ä ÏóÜÏäµÎãàÎã§")
    
    def preprocess_image(self, image_source):
        """Ïù¥ÎØ∏ÏßÄ Ï†ÑÏ≤òÎ¶¨"""
        if isinstance(image_source, str):  # URL
            response = requests.get(image_source, timeout=30)
            response.raise_for_status()
            image_bytes = response.content
        else:  # ÌååÏùº Í∞ùÏ≤¥
            image_bytes = image_source.read()
        
        image = Image.open(io.BytesIO(image_bytes)).convert('RGB')
        image_array = np.array(image)
        
        # 1024x1024Î°ú Î¶¨ÏÇ¨Ïù¥Ï¶à
        if image_array.shape[:2] != (1024, 1024):
            image_array = cv2.resize(image_array, (1024, 1024))
        
        return image_array
    
    def extract_multi_resolution_patches(self, image_array):
        """Î©ÄÌã∞Ìï¥ÏÉÅÎèÑ Ìå®Ïπò Ï∂îÏ∂ú"""
        patches_dict = {}
        
        for patch_size in self.config.patch_sizes:
            patches = extract_patches_paper_way(image_array, patch_size)
            patches_dict[patch_size] = patches
            logger.info(f"üì¶ {patch_size}px: {len(patches)}Í∞ú Ìå®Ïπò Ï∂îÏ∂ú")
        
        return patches_dict
    
    def compute_anomaly_scores(self, patches_dict):
        """Í∞Å Ìï¥ÏÉÅÎèÑÎ≥Ñ Ïù¥ÏÉÅÏ†êÏàò Í≥ÑÏÇ∞"""
        resolution_scores = {}
        detailed_results = {}
        
        from torchvision import transforms
        
        for patch_size, patches in patches_dict.items():
            if patch_size not in self.models or patch_size not in self.reference_db:
                continue
            
            model = self.models[patch_size]
            patch_scores = []
            patch_positions = []
            
            # Î≥ÄÌôò Ï†ïÏùò
            transform = transforms.Compose([
                transforms.ToPILImage(),
                transforms.Resize((patch_size, patch_size)),
                transforms.ToTensor(),
                transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
            ])
            
            # Í∞Å Ìå®ÏπòÎ≥Ñ Ïù¥ÏÉÅÏ†êÏàò Í≥ÑÏÇ∞
            for patch, position in patches:
                try:
                    patch_tensor = transform(patch).unsqueeze(0).to(self.device)
                    
                    with torch.no_grad():
                        features = model.get_features(patch_tensor)
                        features_np = features.cpu().numpy().flatten()
                    
                    # Mahalanobis Í±∞Î¶¨ Í∏∞Î∞ò Ïù¥ÏÉÅÏ†êÏàò Í≥ÑÏÇ∞
                    anomaly_score = self.compute_mahalanobis_score(
                        features_np, patch_size
                    )
                    
                    patch_scores.append(anomaly_score)
                    patch_positions.append(position)
                    
                except Exception as e:
                    logger.warning(f"Ìå®Ïπò Ï≤òÎ¶¨ Ïã§Ìå®: {e}")
                    continue
            
            if patch_scores:
                resolution_scores[patch_size] = max(patch_scores)
                detailed_results[patch_size] = {
                    'scores': patch_scores,
                    'positions': patch_positions,
                    'max_score': max(patch_scores),
                    'avg_score': np.mean(patch_scores),
                    'patch_count': len(patch_scores)
                }
        
        return resolution_scores, detailed_results
    
    def compute_mahalanobis_score(self, features, patch_size):
        """Mahalanobis Í±∞Î¶¨ Í∏∞Î∞ò Ïù¥ÏÉÅÏ†êÏàò Í≥ÑÏÇ∞"""
        ref_data = self.reference_db.get(patch_size)
        if not ref_data:
            return 0.0
        
        mean_features = ref_data['mean_features']
        covariance_matrix = ref_data['covariance_matrix']
        
        # Mahalanobis Í±∞Î¶¨ Í≥ÑÏÇ∞
        diff = features - mean_features
        try:
            inv_cov = np.linalg.pinv(covariance_matrix)
            mahal_dist = np.sqrt(diff.T @ inv_cov @ diff)
            
            # Ï†ïÍ∑úÌôî (0-1 Î≤îÏúÑ)
            normalized_score = min(mahal_dist / 10.0, 1.0)
            
            return float(normalized_score)
        except:
            return 0.0
    
    def compute_final_score(self, resolution_scores):
        """Í∞ÄÏ§ëÏπò Í∏∞Î∞ò ÏµúÏ¢Ö Ïù¥ÏÉÅÏ†êÏàò Í≥ÑÏÇ∞"""
        weighted_score = 0.0
        total_weight = 0.0
        
        for patch_size, weight in self.config.resolution_weights.items():
            if patch_size in resolution_scores:
                weighted_score += weight * resolution_scores[patch_size]
                total_weight += weight
        
        return weighted_score / total_weight if total_weight > 0 else 0.0
    
    def generate_visualization(self, image_array, detailed_results, final_score, result_id):
        """ÏãúÍ∞ÅÌôî ÏÉùÏÑ±"""
        fig, axes = plt.subplots(2, 2, figsize=(15, 15))
        fig.suptitle(f'SwimSimCLR Î©ÄÌã∞Ìï¥ÏÉÅÎèÑ Ïù¥ÏÉÅÌÉêÏßÄ Í≤∞Í≥º (Ï†êÏàò: {final_score:.3f})', 
                    fontsize=16, color='white')
        fig.patch.set_facecolor('black')
        
        # ÏõêÎ≥∏ Ïù¥ÎØ∏ÏßÄ
        axes[0, 0].imshow(image_array)
        axes[0, 0].set_title('ÏõêÎ≥∏ Ïù¥ÎØ∏ÏßÄ', color='white')
        axes[0, 0].axis('off')
        
        # Í∞Å Ìï¥ÏÉÅÎèÑÎ≥Ñ ÌûàÌä∏Îßµ
        for idx, (patch_size, results) in enumerate(detailed_results.items()):
            if idx >= 3:
                break
            
            ax = axes.flatten()[idx + 1]
            
            # ÌûàÌä∏Îßµ ÏÉùÏÑ±
            heatmap = np.zeros((1024, 1024))
            
            for score, (x, y) in zip(results['scores'], results['positions']):
                end_x = min(x + patch_size, 1024)
                end_y = min(y + patch_size, 1024)
                heatmap[y:end_y, x:end_x] = max(heatmap[y:end_y, x:end_x], score)
            
            # Ïò§Î≤ÑÎ†àÏù¥
            ax.imshow(image_array)
            ax.imshow(heatmap, alpha=0.6, cmap='jet', vmin=0, vmax=1)
            ax.set_title(f'{patch_size}px (ÏµúÎåÄ: {results["max_score"]:.3f})', color='white')
            ax.axis('off')
            
            # ÏµúÍ≥† Ï†êÏàò Ìå®Ïπò Î∞ïÏä§
            if results['scores']:
                max_idx = np.argmax(results['scores'])
                max_pos = results['positions'][max_idx]
                rect = patches.Rectangle(
                    max_pos, patch_size, patch_size,
                    linewidth=3, edgecolor='red', facecolor='none'
                )
                ax.add_patch(rect)
        
        # Ï†ÄÏû•
        result_path = os.path.join(self.results_dir, f"result_{result_id}.png")
        plt.savefig(result_path, dpi=150, bbox_inches='tight', 
                   facecolor='black', edgecolor='none')
        plt.close()
        
        return result_path
    
    def analyze_image(self, image_source, **metadata):
        """Î©îÏù∏ Î∂ÑÏÑù Ìï®Ïàò"""
        if not self.is_loaded:
            self.load_models()
        
        start_time = datetime.now()
        
        # Ïù¥ÎØ∏ÏßÄ Ï†ÑÏ≤òÎ¶¨
        image_array = self.preprocess_image(image_source)
        
        # Ìå®Ïπò Ï∂îÏ∂ú
        patches_dict = self.extract_multi_resolution_patches(image_array)
        
        # Ïù¥ÏÉÅÏ†êÏàò Í≥ÑÏÇ∞
        resolution_scores, detailed_results = self.compute_anomaly_scores(patches_dict)
        
        # ÏµúÏ¢Ö Ï†êÏàò
        final_score = self.compute_final_score(resolution_scores)
        
        # Í≤∞Í≥º ID ÏÉùÏÑ±
        import uuid
        result_id = str(uuid.uuid4())
        
        # ÏãúÍ∞ÅÌôî ÏÉùÏÑ±
        visualization_path = self.generate_visualization(
            image_array, detailed_results, final_score, result_id
        )
        
        # Î∂ÑÏÑù ÏãúÍ∞Ñ Í≥ÑÏÇ∞
        analysis_duration = (datetime.now() - start_time).total_seconds()
        
        # Ïù¥ÏÉÅ Ïó¨Î∂Ä ÌåêÏ†ï
        is_abnormal = final_score > self.config.anomaly_threshold
        
        return {
            'result_id': result_id,
            'final_score': final_score,
            'is_abnormal': is_abnormal,
            'threshold': self.config.anomaly_threshold,
            'resolution_scores': {str(k): float(v) for k, v in resolution_scores.items()},
            'detailed_results': {
                str(k): {
                    'max_score': float(v['max_score']),
                    'avg_score': float(v['avg_score']),
                    'patch_count': v['patch_count']
                } for k, v in detailed_results.items()
            },
            'visualization_path': visualization_path,
            'analysis_duration': analysis_duration,
            **metadata
        }

# Ï†ÑÏó≠ ÏÑúÎπÑÏä§ Ïù∏Ïä§ÌÑ¥Ïä§
simclr_service = SimCLRInferenceService()
