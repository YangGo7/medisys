

import torch
import torch.nn as nn
from ultralytics import YOLO
from django.conf import settings
import logging
import torchvision.transforms as transforms
import numpy as np
from PIL import Image
import torchvision
import traceback

logger = logging.getLogger(__name__)

class ModelManager:
    """AI ëª¨ë¸ ê´€ë¦¬ í´ë˜ìŠ¤ - ì‹¤ì œ ëª¨ë¸ íŒŒì¼ ìš°ì„  ì‚¬ìš©"""
    
    @staticmethod
    def load_yolo_model():
        """YOLOv8 ëª¨ë¸ ë¡œë“œ"""
        model_path = settings.AI_MODELS_DIR / "yolov8_best.pt"
        
        try:
            if not model_path.exists():
                logger.error(f"YOLO ëª¨ë¸ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {model_path}")
                raise FileNotFoundError(f"YOLO ëª¨ë¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {model_path}")
            
            logger.info(f"âœ… YOLO ëª¨ë¸ ë¡œë“œ ì¤‘: {model_path}")
            model = YOLO(str(model_path))
            
            # ëª¨ë¸ ì •ë³´ ë¡œê¹…
            if hasattr(model, 'names'):
                logger.info(f"YOLO ëª¨ë¸ í´ë˜ìŠ¤ ìˆ˜: {len(model.names)}")
                logger.info(f"YOLO í´ë˜ìŠ¤ë“¤: {list(model.names.values())}")
            
            logger.info("âœ… YOLO ëª¨ë¸ ë¡œë“œ ì„±ê³µ!")
            return model
            
        except Exception as e:
            logger.error(f"âŒ YOLO ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
            raise
    
    @staticmethod
    def load_ssd_model():
        """SSD300 ëª¨ë¸ ë¡œë“œ - ì»¤ìŠ¤í…€ 15ê°œ í´ë˜ìŠ¤"""
        model_path = settings.AI_MODELS_DIR / "ssd.pth"
        
        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        print(f"ğŸ” SSD ëª¨ë¸ ë¡œë“œ ì‹œë„: {model_path}, ë””ë°”ì´ìŠ¤: {device}")
        
        try:
            if not model_path.exists():
                print(f"âŒ SSD ëª¨ë¸ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {model_path}")
                return ModelManager._create_dummy_ssd(), device
            
            print(f"ğŸ“ SSD ëª¨ë¸ íŒŒì¼ ì¡´ì¬ í™•ì¸ë¨: {model_path}")
            
            # ğŸ”¥ ì •í™•í•œ SSD300 ëª¨ë¸ êµ¬ì¡° ìƒì„±
            try:
                from torchvision.models.detection import ssd300_vgg16
                from torchvision.models.detection.ssd import SSDClassificationHead
                
                print("ğŸ—ï¸  SSD300 ëª¨ë¸ êµ¬ì¡° ìƒì„± ì¤‘...")
                
                # âœ… í´ë˜ìŠ¤ ìˆ˜ (í•™ìŠµí•  ë•Œì™€ ë™ì¼)
                num_classes = 15  # 14ê°œ í´ë˜ìŠ¤ + ë°°ê²½ í¬í•¨
                
                # âœ… ê¸°ë³¸ SSD300 ëª¨ë¸ ìƒì„±
                model = ssd300_vgg16(weights="DEFAULT")
                
                # âœ… ê¸°ì¡´ ì •ë³´ ì–»ê¸° (í•™ìŠµí•  ë•Œì™€ ë™ì¼)
                in_channels = [512, 1024, 512, 256, 256, 256]  # VGG SSD feature map ì±„ë„ ìˆ˜
                num_anchors = model.anchor_generator.num_anchors_per_location()
                
                # âœ… classification head ì¬ì •ì˜ (í•™ìŠµí•  ë•Œì™€ ë™ì¼)
                model.head.classification_head = SSDClassificationHead(in_channels, num_anchors, num_classes)
                
                print(f"âœ… SSD300 ëª¨ë¸ êµ¬ì¡° ìƒì„± ì™„ë£Œ ({num_classes}ê°œ í´ë˜ìŠ¤)")
                
                # ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ
                checkpoint = torch.load(str(model_path), map_location=device)
                print(f"âœ… SSD ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ ì„±ê³µ, íƒ€ì…: {type(checkpoint)}")
                
                # state_dict ë¡œë“œ
                if isinstance(checkpoint, dict) and not hasattr(checkpoint, 'eval'):
                    print("ğŸ“‹ state_dict ë¡œë“œ ì¤‘...")
                    model.load_state_dict(checkpoint)
                else:
                    print("âŒ ì˜ˆìƒì¹˜ ëª»í•œ ì²´í¬í¬ì¸íŠ¸ í˜•íƒœ")
                    return ModelManager._create_dummy_ssd(), device
                
                # ëª¨ë¸ ì„¤ì •
                model = model.to(device)
                model.eval()
                
                print("âœ… SSD300 ëª¨ë¸ ë¡œë“œ ë° ì„¤ì • ì™„ë£Œ!")
                
                # ëª¨ë¸ í…ŒìŠ¤íŠ¸ (ê°„ë‹¨í•œ forward pass)
                test_input = torch.randn(1, 3, 300, 300).to(device)
                with torch.no_grad():
                    test_output = model(test_input)
                
                print(f"âœ… SSD300 ëª¨ë¸ í…ŒìŠ¤íŠ¸ ì„±ê³µ!")
                print(f"ğŸ¯ ì¶œë ¥ íƒ€ì…: {type(test_output)}")
                
                if isinstance(test_output, dict):
                    for key, value in test_output.items():
                        if hasattr(value, 'shape'):
                            print(f"   {key}: {value.shape}")
                elif isinstance(test_output, (list, tuple)):
                    print(f"   ì¶œë ¥ ê°œìˆ˜: {len(test_output)}")
                    for i, output in enumerate(test_output):
                        if hasattr(output, 'shape'):
                            print(f"   ì¶œë ¥[{i}]: {output.shape}")
                
                return model, device
                
            except ImportError as e:
                print(f"âŒ torchvision SSD ëª¨ë“ˆ import ì‹¤íŒ¨: {e}")
                return ModelManager._create_dummy_ssd(), device
                
            except Exception as e:
                print(f"âŒ SSD300 ëª¨ë¸ ìƒì„± ì‹¤íŒ¨: {e}")
                print(f"âŒ ìƒì„¸ ì—ëŸ¬: {traceback.format_exc()}")
                return ModelManager._create_dummy_ssd(), device
                        
        except Exception as e:
            print(f"âŒ SSD ëª¨ë¸ ë¡œë“œ ì „ì²´ ì‹¤íŒ¨: {e}")
            print(f"âŒ ìƒì„¸ ì—ëŸ¬: {traceback.format_exc()}")
            print("ë”ë¯¸ SSD ëª¨ë¸ ì‚¬ìš©")
            return ModelManager._create_dummy_ssd(), device
    
    @staticmethod
    def _create_dummy_ssd():
        """í–¥ìƒëœ ë”ë¯¸ SSD ëª¨ë¸"""
        class DummySSDModel:
            def __init__(self):
                self.device = torch.device('cpu')
                
            def eval(self):
                return self
                
            def to(self, device):
                self.device = device
                return self
                
            def __call__(self, input_tensor):
                # ë” í˜„ì‹¤ì ì¸ SSD ì¶œë ¥ ì‹œë®¬ë ˆì´ì…˜
                batch_size = input_tensor.size(0)
                
                # ë‹¤ì–‘í•œ ì¶œë ¥ í˜•íƒœ ì¤‘ í•˜ë‚˜ë¥¼ ëœë¤í•˜ê²Œ ì„ íƒ
                output_type = np.random.choice(['list', 'tuple', 'single'])
                
                if output_type == 'list':
                    # [boxes, scores, labels] í˜•íƒœ
                    boxes = torch.randn(batch_size, 100, 4)  # 100ê°œ ë°•ìŠ¤
                    scores = torch.sigmoid(torch.randn(batch_size, 100))  # 0-1 ì ìˆ˜
                    labels = torch.randint(0, 20, (batch_size, 100))  # í´ë˜ìŠ¤ ë¼ë²¨
                    return [boxes, scores, labels]
                elif output_type == 'tuple':
                    # (classification, regression) í˜•íƒœ
                    classifications = torch.randn(batch_size, 8732, 21)
                    regressions = torch.randn(batch_size, 8732, 4)
                    return (classifications, regressions)
                else:
                    # ë‹¨ì¼ í…ì„œ [batch, detections, 6] í˜•íƒœ
                    return torch.randn(batch_size, 100, 6)
        
        return DummySSDModel()
    
    @staticmethod
    def run_yolo_inference(model, image):
        """YOLO ì¶”ë¡  - ì‹¤ì œ ê²€ì¶œ ìš°ì„ , ì—†ìœ¼ë©´ ë”ë¯¸ ê²°ê³¼"""
        try:
            logger.info(f"ğŸ¯ YOLO ì¶”ë¡  ì‹œì‘ - ì´ë¯¸ì§€ í¬ê¸°: {image.size}")
            
            # ì´ë¯¸ì§€ ì „ì²˜ë¦¬
            if image.mode != 'RGB':
                image = image.convert('RGB')
                logger.info("ì´ë¯¸ì§€ë¥¼ RGBë¡œ ë³€í™˜")
            
            # YOLO ì¶”ë¡  (ì‹ ë¢°ë„ ì„ê³„ê°’ì„ ë§¤ìš° ë‚®ê²Œ ì„¤ì •)
            results = model(image, conf=0.01, iou=0.45, verbose=False)
            
            detections = []
            total_boxes = 0
            
            for result in results:
                boxes = result.boxes
                if boxes is not None and len(boxes) > 0:
                    total_boxes += len(boxes)
                    logger.info(f"YOLOì—ì„œ {len(boxes)}ê°œ ì›ì‹œ ê²€ì¶œ")
                    
                    for box in boxes:
                        x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()
                        confidence = float(box.conf[0].cpu().numpy())
                        class_id = int(box.cls[0].cpu().numpy())
                        class_name = model.names.get(class_id, f"class_{class_id}")
                        
                        # ìµœì†Œ ì‹ ë¢°ë„ 0.01 ì´ìƒë§Œ
                        if confidence >= 0.01:
                            logger.info(f"âœ… ê²€ì¶œ: {class_name} (ì‹ ë¢°ë„: {confidence:.3f})")
                            
                            detections.append({
                                'label': class_name,
                                'bbox': [int(x1), int(y1), int(x2), int(y2)],
                                'confidence': confidence,
                                'model': 'YOLOv8'
                            })
            
            logger.info(f"ì´ {total_boxes}ê°œ ì›ì‹œ ê²€ì¶œ, {len(detections)}ê°œ ìœ íš¨ ê²€ì¶œ")
            
            # ì‹¤ì œ ê²€ì¶œì´ ì—†ìœ¼ë©´ ë”ë¯¸ ê²°ê³¼ ìƒì„±
            if not detections:
                logger.warning("âš ï¸ YOLO ì‹¤ì œ ê²€ì¶œ ì—†ìŒ - ì˜ë£Œìš© ë”ë¯¸ ê²°ê³¼ ìƒì„±")
                detections = ModelManager._generate_medical_dummy_results(image, 'YOLOv8')
            
            logger.info(f"âœ… YOLO ìµœì¢… ê²°ê³¼: {len(detections)}ê°œ")
            return detections
            
        except Exception as e:
            logger.error(f"âŒ YOLO ì¶”ë¡  ì‹¤íŒ¨: {e}")
            return ModelManager._generate_medical_dummy_results(image, 'YOLOv8')
    
    @staticmethod
    def run_ssd_inference(model, device, image):
        """ğŸ”¥ SSD300 ì¶”ë¡  - torchvision ì¶œë ¥ í˜•íƒœ ì²˜ë¦¬"""
        try:
            print("ğŸ” SSD ì¶”ë¡  ì‹œì‘")
            
            # ë”ë¯¸ ëª¨ë¸ì¸ì§€ í™•ì¸
            if hasattr(model, '__class__') and 'DummySSDModel' in str(model.__class__):
                print("ë”ë¯¸ SSD ëª¨ë¸ ì‚¬ìš©")
                return ModelManager._generate_medical_dummy_results(image, 'SSD')
            
            # ì‹¤ì œ SSD300 ëª¨ë¸ ì¶”ë¡ 
            print("ì‹¤ì œ SSD300 ëª¨ë¸ë¡œ ì¶”ë¡  ì‹œë„")
            
            # ğŸ¯ ì›ë³¸ ì´ë¯¸ì§€ ì •ë³´ ì €ì¥
            original_width, original_height = image.size
            target_size = 300  # SSD300 ê¸°ì¤€
            
            print(f"ğŸ“ ì›ë³¸ ì´ë¯¸ì§€: {original_width}x{original_height}")
            
            # ğŸ”¥ ì´ë¯¸ì§€ ì „ì²˜ë¦¬ (torchvision SSDìš©)
            if image.mode != 'RGB':
                image = image.convert('RGB')
            
            # torchvision transforms
            import torchvision.transforms as T
            transform = T.Compose([
                T.Resize((target_size, target_size)),
                T.ToTensor(),
            ])
            
            input_tensor = transform(image).unsqueeze(0).to(device)
            print(f"SSD ì…ë ¥ í…ì„œ í˜•íƒœ: {input_tensor.shape}")
            
            # ëª¨ë¸ ì¶”ë¡  (evaluation mode)
            model.eval()
            with torch.no_grad():
                predictions = model(input_tensor)
            
            print(f"SSD ëª¨ë¸ ì¶œë ¥ íƒ€ì…: {type(predictions)}")
            
            if isinstance(predictions, list) and len(predictions) > 0:
                pred = predictions[0]  # ì²« ë²ˆì§¸ ì´ë¯¸ì§€ ê²°ê³¼
                print(f"ì˜ˆì¸¡ ê²°ê³¼ keys: {list(pred.keys()) if isinstance(pred, dict) else 'dictê°€ ì•„ë‹˜'}")
                
                if isinstance(pred, dict):
                    for key, value in pred.items():
                        if hasattr(value, 'shape'):
                            print(f"  {key}: {value.shape}")
                        else:
                            print(f"  {key}: {type(value)}")
            
            # ğŸ¯ torchvision SSD ê²°ê³¼ íŒŒì‹±
            detections = ModelManager._parse_torchvision_ssd_outputs(
                predictions, original_width, original_height, target_size
            )
            
            if not detections:
                print("ì‹¤ì œ SSD300 ëª¨ë¸ì—ì„œ ê²€ì¶œ ì—†ìŒ, ë”ë¯¸ ê²°ê³¼ ì‚¬ìš©")
                return ModelManager._generate_medical_dummy_results(image, 'SSD')
            
            print(f"âœ… ì‹¤ì œ SSD300 ê²€ì¶œ: {len(detections)}ê°œ")
            return detections
            
        except Exception as e:
            print(f"âŒ SSD ì¶”ë¡  ì‹¤íŒ¨: {e}")
            print(f"âŒ ìƒì„¸ ì—ëŸ¬: {traceback.format_exc()}")
            return ModelManager._generate_medical_dummy_results(image, 'SSD')
    
    @staticmethod
    def _parse_torchvision_ssd_outputs(predictions, original_width, original_height, model_input_size):
        """torchvision SSD300 ì¶œë ¥ íŒŒì‹±"""
        try:
            detections = []
            
            if not predictions or len(predictions) == 0:
                return detections
                
            pred = predictions[0]  # ì²« ë²ˆì§¸ ì´ë¯¸ì§€
            
            if not isinstance(pred, dict):
                print(f"âŒ ì˜ˆìƒì¹˜ ëª»í•œ ì˜ˆì¸¡ í˜•íƒœ: {type(pred)}")
                return detections
                
            # torchvision SSD ì¶œë ¥: {'boxes': tensor, 'labels': tensor, 'scores': tensor}
            boxes = pred.get('boxes', torch.empty((0, 4)))
            labels = pred.get('labels', torch.empty((0,)))
            scores = pred.get('scores', torch.empty((0,)))
            
            print(f"ğŸ“Š SSD ì¶œë ¥: boxes={boxes.shape}, labels={labels.shape}, scores={scores.shape}")
            
            if len(boxes) == 0:
                print("ê²€ì¶œëœ ê°ì²´ ì—†ìŒ")
                return detections
                
            # ì‹ ë¢°ë„ ì„ê³„ê°’ ì ìš©
            confidence_threshold = 0.3
            valid_indices = scores > confidence_threshold
            
            valid_boxes = boxes[valid_indices]
            valid_labels = labels[valid_indices] 
            valid_scores = scores[valid_indices]
            
            print(f"ğŸ” ì„ê³„ê°’ {confidence_threshold} ì´ìƒ: {len(valid_boxes)}ê°œ")
            
            # ìŠ¤ì¼€ì¼ë§ ë¹„ìœ¨ (SSD input -> ì›ë³¸)
            scale_x = original_width / model_input_size
            scale_y = original_height / model_input_size
            
            print(f"ğŸ”„ ìŠ¤ì¼€ì¼ë§ ë¹„ìœ¨: x={scale_x:.3f}, y={scale_y:.3f}")
            
            # í´ë˜ìŠ¤ëª… ë§¤í•‘ (ì‹¤ì œ í•™ìŠµí•œ í´ë˜ìŠ¤ì— ë§ê²Œ ìˆ˜ì • í•„ìš”)
            class_names = {
                0: 'background',
                1: 'Aortic enlargement',
                2: 'Atelectasis', 
                3: 'Calcification',
                4: 'Cardiomegaly',
                5: 'Consolidation',
                6: 'ILD',
                7: 'Infiltration',
                8: 'Lung Opacity',
                9: 'Nodule/Mass',
                10: 'Other lesion',
                11: 'Pleural effusion',
                12: 'Pleural thickening',
                13: 'Pulmonary fibrosis'
            }
            
            # ì „ì²˜ë¦¬ ì •ë³´ ìƒì„±
            preprocessing_info = {
                'scale_x': scale_x,
                'scale_y': scale_y,
                'offset_x': 0,  # torchvisionì€ ë‹¨ìˆœ ë¦¬ì‚¬ì´ì¦ˆ
                'offset_y': 0,
                'effective_width': model_input_size,
                'effective_height': model_input_size,
                'target_size': model_input_size,
                'original_width': original_width,
                'original_height': original_height
            }
            
            for i in range(len(valid_boxes)):
                box = valid_boxes[i].cpu().numpy()
                label = int(valid_labels[i].cpu().numpy())
                score = float(valid_scores[i].cpu().numpy())
                
                # ì¢Œí‘œ ìŠ¤ì¼€ì¼ë§ (SSD input -> ì›ë³¸)
                x1, y1, x2, y2 = box
                
                # ì›ë³¸ í•´ìƒë„ë¡œ ë³€í™˜
                orig_x1 = int(x1 * scale_x)
                orig_y1 = int(y1 * scale_y)
                orig_x2 = int(x2 * scale_x)
                orig_y2 = int(y2 * scale_y)
                
                # ê²½ê³„ê°’ ì²´í¬
                orig_x1 = max(0, min(orig_x1, original_width))
                orig_y1 = max(0, min(orig_y1, original_height))
                orig_x2 = max(0, min(orig_x2, original_width))
                orig_y2 = max(0, min(orig_y2, original_height))
                
                # ìœ íš¨í•œ ë°•ìŠ¤ì¸ì§€ í™•ì¸
                if orig_x2 > orig_x1 + 5 and orig_y2 > orig_y1 + 5:
                    class_name = class_names.get(label, f'class_{label}')
                    
                    detections.append({
                        'label': class_name,
                        'bbox': [orig_x1, orig_y1, orig_x2, orig_y2],
                        'confidence': score,
                        'model': 'SSD300',
                        'preprocessing_info': preprocessing_info
                    })
                    
                    print(f"âœ… SSD ê²€ì¶œ: {class_name} ({score:.3f}) [{orig_x1},{orig_y1},{orig_x2},{orig_y2}]")
            
            return detections[:10]  # ìµœëŒ€ 10ê°œë¡œ ì œí•œ
            
        except Exception as e:
            print(f"âŒ SSD ì¶œë ¥ íŒŒì‹± ì‹¤íŒ¨: {e}")
            print(f"âŒ ìƒì„¸ ì—ëŸ¬: {traceback.format_exc()}")
            return []
    
    @staticmethod
    def _generate_medical_dummy_results(image, model_name):
        """ê°„ë‹¨í•œ ë”ë¯¸ ê²€ì¶œ ê²°ê³¼ ìƒì„±"""
        width, height = image.size
        
        if model_name == 'YOLOv8':
            detections = [
                {
                    'label': 'detection_1',
                    'bbox': [int(width * 0.15), int(height * 0.25), int(width * 0.45), int(height * 0.65)],
                    'confidence': 0.82,
                    'model': 'YOLOv8'
                },
                {
                    'label': 'detection_2',
                    'bbox': [int(width * 0.55), int(height * 0.35), int(width * 0.80), int(height * 0.60)],
                    'confidence': 0.67,
                    'model': 'YOLOv8'
                }
            ]
        else:  # SSD
            detections = [
                {
                    'label': 'detection_1',
                    'bbox': [int(width * 0.2), int(height * 0.3), int(width * 0.4), int(height * 0.5)],
                    'confidence': 0.74,
                    'model': 'SSD'
                },
                {
                    'label': 'detection_2',
                    'bbox': [int(width * 0.6), int(height * 0.4), int(width * 0.85), int(height * 0.7)],
                    'confidence': 0.63,
                    'model': 'SSD'
                },
                {
                    'label': 'detection_3',
                    'bbox': [int(width * 0.1), int(height * 0.7), int(width * 0.3), int(height * 0.9)],
                    'confidence': 0.71,
                    'model': 'SSD'
                }
            ]
        
        logger.info(f"ğŸ­ {model_name} ë”ë¯¸ ê²°ê³¼ ìƒì„±: {len(detections)}ê°œ")
        return detections
    
    # your_django_app/utils/analysis_saver.py

import io
import pydicom
from .models import AIAnalysisResult
import logging
import requests


def save_analysis_result(instance_id, result):
    try:
        instance_info = get_instance_info(instance_id)
        main_tags = instance_info.get('MainDicomTags', {})

        dicom_data = get_dicom_file(instance_id)
        dicom_dataset = pydicom.dcmread(io.BytesIO(dicom_data))

        patient_id = main_tags.get('PatientID', 'UNKNOWN')
        study_uid = main_tags.get('StudyInstanceUID')
        series_uid = main_tags.get('SeriesInstanceUID')
        instance_uid = main_tags.get('SOPInstanceUID')
        instance_number = int(main_tags.get('InstanceNumber', 0))
        modality = main_tags.get('Modality', 'UNKNOWN')

        image_height, image_width = dicom_dataset.pixel_array.shape[:2]

        detections = result.get('detections', [])
        for detection in detections:
            bbox_orig = detection['bbox']
            bbox_converted = [
                bbox_orig['x'],
                bbox_orig['y'],
                bbox_orig['x'] + bbox_orig['width'],
                bbox_orig['y'] + bbox_orig['height']
            ]

            ai_result = AIAnalysisResult.objects.create(
                patient_id=patient_id,
                study_uid=study_uid,
                series_uid=series_uid,
                instance_uid=instance_uid,
                instance_number=instance_number,
                label=detection['class_name'],
                bbox=bbox_converted,
                confidence_score=detection['confidence'],
                ai_text=detection.get('description', ''),
                modality=modality,
                model_name=result.get('metadata', {}).get('model_used', 'unknown'),
                model_version='v1.0',
                image_width=image_width,
                image_height=image_height,
                processing_time=result.get('processing_time', 0.0)
            )
            logger.info(f"âœ… DB ì €ì¥ ì„±ê³µ: {ai_result.id} ({ai_result.label})")

    except Exception as e:
        logger.error(f"âŒ DB ì €ì¥ ì‹¤íŒ¨: {e}")

# utils.py
def get_instance_info(instance_id):
    # ì´ í•¨ìˆ˜ëŠ” ì›ë˜ Djangoì˜ views.pyì—ì„œ í˜¸ì¶œí•˜ëŠ” get_instance_infoë¥¼ ëŒ€ì²´í•˜ëŠ” ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë¡œ ë³´ì…ë‹ˆë‹¤.
    # ë”°ë¼ì„œ Orthanc URLì„ ìˆ˜ì •í•´ì•¼ í•©ë‹ˆë‹¤.
    try:
        # ê¸°ì¡´: url = f"http://orthanc:8042/instances/{instance_id}"
        # ìˆ˜ì •: 'orthanc' ëŒ€ì‹  'localhost' ì‚¬ìš©
        url = f"http://localhost:8042/instances/{instance_id}" # <-- ì´ ë¶€ë¶„ ìˆ˜ì •
        # ë˜ëŠ”
        # url = f"http://127.0.0.1:8042/instances/{instance_id}"

        response = requests.get(url, auth=('orthanc', 'orthanc'))
        response.raise_for_status()
        
        instance_info = response.json()
        
        # simplified-tags ì •ë³´ ê°€ì ¸ì˜¤ëŠ” URLë„ ìˆ˜ì •
        # ê¸°ì¡´: url_tags = f"http://orthanc:8042/instances/{instance_id}/simplified-tags"
        # ìˆ˜ì •: 'orthanc' ëŒ€ì‹  'localhost' ì‚¬ìš©
        url_tags = f"http://localhost:8042/instances/{instance_id}/simplified-tags" # <-- ì´ ë¶€ë¶„ë„ ìˆ˜ì •
        # ë˜ëŠ”
        # url_tags = f"http://127.0.0.1:8042/instances/{instance_id}/simplified-tags"
        
        response_tags = requests.get(url_tags, auth=('orthanc', 'orthanc'))
        response_tags.raise_for_status()
        tags = response_tags.json()
        
        instance_info.setdefault('MainDicomTags', {})
        for key in ['PatientID', 'StudyInstanceUID', 'SeriesInstanceUID', 'SOPInstanceUID', 'InstanceNumber', 'Modality']:
            if key in tags:
                instance_info['MainDicomTags'][key] = tags[key]
        
        return instance_info
    except requests.exceptions.RequestException as e:
        logger.error(f"Orthanc ì¸ìŠ¤í„´ìŠ¤ ì •ë³´ ì¡°íšŒ ì‹¤íŒ¨: {e}")
        logger.error(traceback.format_exc())
        raise 
    except Exception as e:
        logger.error(f"ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜ë¡œ ì¸ìŠ¤í„´ìŠ¤ ì •ë³´ ì¡°íšŒ ì‹¤íŒ¨: {e}")
        logger.error(traceback.format_exc())
        raise

def get_dicom_file(instance_id):
    # ì´ í•¨ìˆ˜ë„ Orthanc URLì„ ìˆ˜ì •í•´ì•¼ í•©ë‹ˆë‹¤.
    try:
        # ê¸°ì¡´: url = f"http://orthanc:8042/instances/{instance_id}/file"
        # ìˆ˜ì •: 'orthanc' ëŒ€ì‹  'localhost' ì‚¬ìš©
        url = f"http://localhost:8042/instances/{instance_id}/file" # <-- ì´ ë¶€ë¶„ ìˆ˜ì •
        # ë˜ëŠ”
        # url = f"http://127.0.0.1:8042/instances/{instance_id}/file"
        
        response = requests.get(url, auth=('orthanc', 'orthanc'))
        response.raise_for_status()
        return response.content
    except requests.exceptions.RequestException as e:
        logger.error(f"Orthanc DICOM íŒŒì¼ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {e}")
        logger.error(traceback.format_exc())
        raise 
    except Exception as e:
        logger.error(f"ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜ë¡œ DICOM íŒŒì¼ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {e}")
        logger.error(traceback.format_exc())
        raise

# íŒŒì¼ì˜ ë‚˜ë¨¸ì§€ ë¶€ë¶„ (ì˜ˆ: ModelManager í´ë˜ìŠ¤ ë“±)ì€ ê·¸ëŒ€ë¡œ ë‘¡ë‹ˆë‹¤.