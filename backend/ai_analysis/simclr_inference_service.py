# backend/ai_services/simclr_inference_service.py
# GradCAM Generator ìˆ˜ì • - gradient ê³„ì‚° ë¬¸ì œ í•´ê²°

import torch
import torch.nn as nn
import torch.nn.functional as F
import numpy as np
import cv2
import pickle
import logging
from typing import Dict, List, Tuple, Optional
from torchvision import transforms
from torchvision.models import efficientnet_b2, EfficientNet_B2_Weights
import faiss
from pathlib import Path
import json
from datetime import datetime
import base64
from io import BytesIO
from PIL import Image
import matplotlib.pyplot as plt
import matplotlib.cm as cm

logger = logging.getLogger(__name__)

class EfficientNetSimCLR(nn.Module):
    """SimCLR_Patched GitHubì™€ ì™„ì „íˆ ë™ì¼í•œ ëª¨ë¸ êµ¬ì¡°"""
    def __init__(self, feature_dim=384, projection_dim=128):
        super(EfficientNetSimCLR, self).__init__()
        
        # ì›ë³¸ê³¼ ë™ì¼í•œ EfficientNet-B2 ë°±ë³¸
        self.efficientnet = efficientnet_b2(weights=EfficientNet_B2_Weights.IMAGENET1K_V1)
        
        # EfficientNetì˜ íŠ¹ì§• ì¶”ì¶œ ë¶€ë¶„ë§Œ ì‚¬ìš© (classifier ì œê±°)
        self.encoder = nn.Sequential(*list(self.efficientnet.children())[:-1])
        self.feature_dim = 1408  # EfficientNet-B2ì˜ ì¶œë ¥ ì°¨ì›
        
        # ì ì‘í˜• í‰ê·  í’€ë§
        self.adaptive_pool = nn.AdaptiveAvgPool2d((1, 1))
        
        # Projection head (ì›ë³¸ê³¼ ë™ì¼)
        self.projection = nn.Sequential(
            nn.Linear(self.feature_dim, feature_dim),
            nn.BatchNorm1d(feature_dim),
            nn.SiLU(inplace=True),  # Swish í™œì„±í™” í•¨ìˆ˜
            nn.Dropout(0.2),
            nn.Linear(feature_dim, projection_dim),
            nn.BatchNorm1d(projection_dim),
        )
        
        # ê°€ì¤‘ì¹˜ ì´ˆê¸°í™”
        self._initialize_weights()
        
    def _initialize_weights(self):
        """EfficientNet ìŠ¤íƒ€ì¼ ê°€ì¤‘ì¹˜ ì´ˆê¸°í™”"""
        for m in self.modules():
            if isinstance(m, nn.Linear):
                nn.init.trunc_normal_(m.weight, std=0.02)
                if m.bias is not None:
                    nn.init.constant_(m.bias, 0)
            elif isinstance(m, nn.BatchNorm1d):
                nn.init.constant_(m.weight, 1)
                nn.init.constant_(m.bias, 0)
    
    def forward(self, x):
        # EfficientNet íŠ¹ì§• ì¶”ì¶œ
        h = self.encoder(x)
        h = self.adaptive_pool(h)
        h = h.flatten(1)
        
        # Projection head í†µê³¼
        z = self.projection(h)
        
        # L2 ì •ê·œí™”
        return F.normalize(z, dim=-1)
    
    def get_features(self, x):
        """íŠ¹ì§• ì¶”ì¶œ (projection ì´ì „) - ì¶”ë¡ ìš©"""
        with torch.no_grad():
            h = self.encoder(x)
            h = self.adaptive_pool(h)
            h = h.flatten(1)
        return h
    
    def get_conv_features(self, x):
        """Grad-CAMì„ ìœ„í•œ convolutional features"""
        # EfficientNetì˜ ë§ˆì§€ë§‰ convolutional layerê¹Œì§€ë§Œ í†µê³¼
        features = x
        for i, layer in enumerate(self.efficientnet.features):
            features = layer(features)
        return features

class GradCAMGenerator:
    """ìˆ˜ì •ëœ Grad-CAM ìƒì„±ê¸° (gradient ë¬¸ì œ í•´ê²°)"""
    
    def __init__(self, model, device='cpu'):
        self.model = model
        self.device = device
        self.gradients = None
        self.activations = None
        
        # EfficientNetì˜ ë§ˆì§€ë§‰ conv layerì— hook ë“±ë¡
        self.target_layer = self.model.efficientnet.features[-1]
        self.target_layer.register_forward_hook(self._save_activation)
        self.target_layer.register_backward_hook(self._save_gradient)
    
    def _save_activation(self, module, input, output):
        self.activations = output
    
    def _save_gradient(self, module, grad_input, grad_output):
        self.gradients = grad_output[0]
    
    def generate_cam(self, input_tensor, class_idx=None):
        """ìˆ˜ì •ëœ Grad-CAM ìƒì„± (gradient ë¬¸ì œ í•´ê²°)"""
        try:
            self.model.eval()
            
            # ğŸ”¥ input_tensorê°€ gradientë¥¼ ìš”êµ¬í•˜ë„ë¡ ì„¤ì •
            if not input_tensor.requires_grad:
                input_tensor = input_tensor.requires_grad_(True)
            
            # Forward pass through conv featuresë§Œ (projection ì œì™¸)
            conv_features = self.model.get_conv_features(input_tensor)  # [1, C, H, W]
            
            # ğŸ”¥ ê°„ë‹¨í•œ anomaly score ê³„ì‚° (gradient í˜¸í™˜)
            # Conv featuresì˜ ê° ì±„ë„ë³„ í‰ê· ì„ ê³„ì‚°í•˜ì—¬ ì´ìƒë„ë¡œ ì‚¬ìš©
            pooled_features = F.adaptive_avg_pool2d(conv_features, (1, 1))  # [1, C, 1, 1]
            flattened = pooled_features.flatten(1)  # [1, C]
            
            # íŠ¹ì§•ì˜ L2 normì„ ì´ìƒë„ë¡œ ì‚¬ìš© (gradient ê³„ì‚° ê°€ëŠ¥)
            anomaly_score = torch.norm(flattened, dim=1).mean()
            
            # ğŸ”¥ anomaly_scoreê°€ gradientë¥¼ ìš”êµ¬í•˜ëŠ”ì§€ í™•ì¸
            if not anomaly_score.requires_grad:
                logger.warning("anomaly_scoreê°€ gradientë¥¼ ìš”êµ¬í•˜ì§€ ì•ŠìŒ, ë‹¨ìˆœ CAM ìƒì„±")
                return self._generate_simple_cam(conv_features)
            
            # Backward pass
            self.model.zero_grad()
            anomaly_score.backward(retain_graph=True)
            
            # Grad-CAM ê³„ì‚°
            gradients = self.gradients  # [1, C, H, W]
            activations = self.activations  # [1, C, H, W]
            
            if gradients is None or activations is None:
                logger.warning("Gradients ë˜ëŠ” activationsê°€ None, ë‹¨ìˆœ CAM ìƒì„±")
                return self._generate_simple_cam(conv_features)
            
            # Global average pooling of gradients
            weights = torch.mean(gradients[0], dim=(1, 2))  # [C]
            
            # Weighted combination
            cam = torch.zeros(activations.shape[2:], device=self.device)
            for i, w in enumerate(weights):
                cam += w * activations[0, i, :, :]
            
            # ReLU and normalize
            cam = F.relu(cam)
            if cam.max() > 0:
                cam = cam / cam.max()
            
            return cam.detach().cpu().numpy()
            
        except Exception as e:
            logger.error(f"Grad-CAM ìƒì„± ì˜¤ë¥˜: {e}")
            # Fallback: ë‹¨ìˆœ CAM ìƒì„±
            return self._generate_simple_cam_fallback(input_tensor)
    
    def _generate_simple_cam(self, conv_features):
        """ë‹¨ìˆœ CAM ìƒì„± (gradient ì—†ì´)"""
        try:
            # Conv featuresì˜ ì±„ë„ë³„ í‰ê· ì„ CAMìœ¼ë¡œ ì‚¬ìš©
            cam = torch.mean(conv_features[0], dim=0)  # [H, W]
            
            # ì •ê·œí™”
            cam = F.relu(cam)
            if cam.max() > 0:
                cam = cam / cam.max()
            
            return cam.detach().cpu().numpy()
            
        except Exception as e:
            logger.error(f"ë‹¨ìˆœ CAM ìƒì„± ì˜¤ë¥˜: {e}")
            # ìµœì¢… fallback: ê· ì¼í•œ CAM
            return np.ones((7, 7), dtype=np.float32) * 0.5
    
    def _generate_simple_cam_fallback(self, input_tensor):
        """ìµœì¢… fallback CAM ìƒì„±"""
        try:
            # ì…ë ¥ ì´ë¯¸ì§€ í¬ê¸° ê¸°ì¤€ìœ¼ë¡œ ê¸°ë³¸ CAM ìƒì„±
            height, width = input_tensor.shape[2], input_tensor.shape[3]
            cam_height, cam_width = height // 32, width // 32  # ëŒ€ëµì ì¸ feature map í¬ê¸°
            
            # ì¤‘ì•™ì´ ì¡°ê¸ˆ ë” ë°ì€ CAM ìƒì„±
            y, x = np.ogrid[:cam_height, :cam_width]
            center_y, center_x = cam_height // 2, cam_width // 2
            cam = np.exp(-((x - center_x) ** 2 + (y - center_y) ** 2) / (2.0 * (min(cam_height, cam_width) / 4) ** 2))
            
            return cam.astype(np.float32)
            
        except Exception as e:
            logger.error(f"Fallback CAM ìƒì„± ì˜¤ë¥˜: {e}")
            return np.ones((7, 7), dtype=np.float32) * 0.5

class SimCLRPatchInference:
    """SimCLR íŒ¨ì¹˜ ê¸°ë°˜ ì´ìƒíƒì§€ ì¶”ë¡  (gradient ë¬¸ì œ í•´ê²° ë²„ì „)"""
    
    def __init__(self, model_path: str, features_path: str, device='cpu'):
        self.device = device
        self.model = None
        self.reference_features = None
        self.faiss_index = None
        self.grad_cam = None
        
        # ì´ë¯¸ì§€ ì „ì²˜ë¦¬ (í•™ìŠµ ì‹œì™€ ë™ì¼)
        self.transform = transforms.Compose([
            transforms.Resize((224, 224)),
            transforms.ToTensor(),
            transforms.Normalize(
                mean=[0.485, 0.456, 0.406],
                std=[0.229, 0.224, 0.225]
            )
        ])
        
        self._load_model(model_path)
        self._load_features(features_path)
        
    def _load_model(self, model_path: str):
        """ëª¨ë¸ ë¡œë“œ (ì›ë³¸ êµ¬ì¡°ì™€ í˜¸í™˜)"""
        try:
            checkpoint = torch.load(model_path, map_location=self.device)
            
            # ëª¨ë¸ ì„¤ì • ì¶”ì¶œ
            model_config = checkpoint.get('model_config', {})
            feature_dim = model_config.get('feature_dim', 384)
            projection_dim = model_config.get('projection_dim', 128)
            
            logger.info(f"ğŸ“Š ëª¨ë¸ ì„¤ì •: feature_dim={feature_dim}, projection_dim={projection_dim}")
            
            # ëª¨ë¸ ìƒì„±
            self.model = EfficientNetSimCLR(feature_dim, projection_dim)
            
            # state_dict ë¡œë“œ
            try:
                self.model.load_state_dict(checkpoint['model_state_dict'], strict=True)
                logger.info("âœ… ëª¨ë¸ ê°€ì¤‘ì¹˜ ë¡œë“œ ì„±ê³µ (strict mode)")
            except RuntimeError as e:
                logger.warning(f"âš ï¸ Strict ëª¨ë“œ ì‹¤íŒ¨, ë¶€ë¶„ ë¡œë“œ ì‹œë„: {e}")
                model_dict = self.model.state_dict()
                pretrained_dict = {k: v for k, v in checkpoint['model_state_dict'].items() 
                                 if k in model_dict and v.size() == model_dict[k].size()}
                model_dict.update(pretrained_dict)
                self.model.load_state_dict(model_dict)
                logger.info(f"âœ… ë¶€ë¶„ ëª¨ë¸ ë¡œë“œ ì„±ê³µ: {len(pretrained_dict)}/{len(model_dict)} ë ˆì´ì–´")
            
            self.model.to(self.device)
            self.model.eval()
            
            # Grad-CAM ì´ˆê¸°í™”
            self.grad_cam = GradCAMGenerator(self.model, self.device)
            
            logger.info(f"âœ… SimCLR ëª¨ë¸ ë¡œë“œ ì™„ë£Œ: {model_path}")
            
        except Exception as e:
            logger.error(f"âŒ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
            logger.exception("ìƒì„¸ ì˜¤ë¥˜:")
            raise
    
    def _load_features(self, features_path: str):
        """ì •ìƒ íŠ¹ì§•ë²¡í„° ë¡œë“œ"""
        try:
            with open(features_path, 'rb') as f:
                features_data = pickle.load(f)
            
            # íŠ¹ì§•ë²¡í„° ì¶”ì¶œ
            if isinstance(features_data, dict):
                self.reference_features = features_data.get('features', features_data)
            else:
                self.reference_features = features_data
            
            # numpy arrayë¡œ ë³€í™˜
            if isinstance(self.reference_features, list):
                self.reference_features = np.array(self.reference_features)
            
            # FAISS ì¸ë±ìŠ¤ êµ¬ì„±
            dimension = self.reference_features.shape[1]
            self.faiss_index = faiss.IndexFlatL2(dimension)
            self.faiss_index.add(self.reference_features.astype(np.float32))
            
            logger.info(f"âœ… ì •ìƒ íŠ¹ì§•ë²¡í„° ë¡œë“œ ì™„ë£Œ: {self.reference_features.shape[0]}ê°œ íŒ¨ì¹˜, ì°¨ì›: {dimension}")
            
        except Exception as e:
            logger.error(f"âŒ íŠ¹ì§•ë²¡í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
            raise
    
    def extract_patches(self, image: np.ndarray, patch_size: int = 224, stride: int = 112):
        """ì´ë¯¸ì§€ì—ì„œ íŒ¨ì¹˜ ì¶”ì¶œ (í•™ìŠµ ì‹œì™€ ë™ì¼í•œ ë°©ì‹)"""
        h, w = image.shape[:2]
        patches = []
        positions = []
        
        for y in range(0, h - patch_size + 1, stride):
            for x in range(0, w - patch_size + 1, stride):
                patch = image[y:y+patch_size, x:x+patch_size]
                if patch.shape[:2] == (patch_size, patch_size):
                    patches.append(patch)
                    positions.append((x, y, x+patch_size, y+patch_size))
        
        return patches, positions
    
    def compute_patch_anomaly_scores(self, patches: List[np.ndarray]) -> np.ndarray:
        """íŒ¨ì¹˜ë“¤ì˜ ì´ìƒë„ ì ìˆ˜ ê³„ì‚°"""
        anomaly_scores = []
        
        for patch in patches:
            # íŒ¨ì¹˜ë¥¼ PIL Imageë¡œ ë³€í™˜
            if len(patch.shape) == 2:  # ê·¸ë ˆì´ìŠ¤ì¼€ì¼
                patch_pil = Image.fromarray(patch).convert('RGB')
            else:
                patch_pil = Image.fromarray(patch)
            
            # ì „ì²˜ë¦¬
            patch_tensor = self.transform(patch_pil).unsqueeze(0).to(self.device)
            
            # íŠ¹ì§• ì¶”ì¶œ (projection ì´ì „ì˜ features ì‚¬ìš©)
            with torch.no_grad():
                features = self.model.get_features(patch_tensor)
                features_np = features.cpu().numpy().astype(np.float32)
            
            # FAISSë¡œ ìµœê·¼ì ‘ ì´ì›ƒ ê±°ë¦¬ ê³„ì‚°
            distances, _ = self.faiss_index.search(features_np, k=1)
            anomaly_score = distances[0][0]  # L2 ê±°ë¦¬
            
            anomaly_scores.append(anomaly_score)
        
        return np.array(anomaly_scores)
    
    def generate_heatmap(self, image: np.ndarray, patches: List[np.ndarray], 
                        positions: List[Tuple], anomaly_scores: np.ndarray) -> np.ndarray:
        """ì´ìƒë„ íˆíŠ¸ë§µ ìƒì„±"""
        h, w = image.shape[:2]
        heatmap = np.zeros((h, w), dtype=np.float32)
        count_map = np.zeros((h, w), dtype=np.float32)
        
        # ê° íŒ¨ì¹˜ì˜ ì´ìƒë„ë¥¼ í•´ë‹¹ ìœ„ì¹˜ì— ëˆ„ì 
        for (x1, y1, x2, y2), score in zip(positions, anomaly_scores):
            heatmap[y1:y2, x1:x2] += score
            count_map[y1:y2, x1:x2] += 1
        
        # í‰ê· í™” (ê²¹ì¹˜ëŠ” ë¶€ë¶„)
        mask = count_map > 0
        heatmap[mask] = heatmap[mask] / count_map[mask]
        
        # ì •ê·œí™”
        if heatmap.max() > 0:
            heatmap = heatmap / heatmap.max()
        
        return heatmap
    
    def generate_gradcam_for_image(self, image: np.ndarray) -> np.ndarray:
        """ì „ì²´ ì´ë¯¸ì§€ì— ëŒ€í•œ Grad-CAM ìƒì„± (ì•ˆì „í•œ ë²„ì „)"""
        try:
            # ì´ë¯¸ì§€ ì „ì²˜ë¦¬
            if len(image.shape) == 2:
                image_pil = Image.fromarray(image).convert('RGB')
            else:
                image_pil = Image.fromarray(image)
            
            # 224x224ë¡œ ë¦¬ì‚¬ì´ì¦ˆ
            image_resized = image_pil.resize((224, 224))
            input_tensor = self.transform(image_resized).unsqueeze(0).to(self.device)
            
            # ğŸ”¥ gradient ê³„ì‚°ì„ ìœ„í•œ ì„¤ì •
            input_tensor.requires_grad_(True)
            
            # Grad-CAM ìƒì„±
            cam = self.grad_cam.generate_cam(input_tensor)
            
            # ì›ë³¸ í¬ê¸°ë¡œ ë³µì›
            cam_resized = cv2.resize(cam, (image.shape[1], image.shape[0]))
            
            return cam_resized
            
        except Exception as e:
            logger.error(f"Grad-CAM ìƒì„± ì˜¤ë¥˜: {e}")
            # Fallback: íŒ¨ì¹˜ ê¸°ë°˜ íˆíŠ¸ë§µ ì‚¬ìš©
            logger.info("Fallback: íŒ¨ì¹˜ ê¸°ë°˜ íˆíŠ¸ë§µ ì‚¬ìš©")
            return np.ones((image.shape[0], image.shape[1]), dtype=np.float32) * 0.5
    
    # backend/ai_services/simclr_inference_service.py
# analyze_image ë©”ì„œë“œì˜ JSON ì§ë ¬í™” ë¶€ë¶„ë§Œ ìˆ˜ì •

    def analyze_image(self, image: np.ndarray) -> Dict:
        """ì´ë¯¸ì§€ ë¶„ì„ (íŒ¨ì¹˜ ê¸°ë°˜ + ì•ˆì „í•œ Grad-CAM) - JSON ì§ë ¬í™” ì•ˆì „ ë²„ì „"""
        try:
            logger.info(f"ğŸ” ì´ë¯¸ì§€ ë¶„ì„ ì‹œì‘: shape={image.shape}")
            
            # 1. íŒ¨ì¹˜ ì¶”ì¶œ
            patches, positions = self.extract_patches(image)
            
            if not patches:
                return {
                    'status': 'error',
                    'message': 'íŒ¨ì¹˜ë¥¼ ì¶”ì¶œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.'
                }
            
            logger.info(f"ğŸ“‹ íŒ¨ì¹˜ ì¶”ì¶œ ì™„ë£Œ: {len(patches)}ê°œ")
            
            # 2. íŒ¨ì¹˜ë³„ ì´ìƒë„ ê³„ì‚°
            anomaly_scores = self.compute_patch_anomaly_scores(patches)
            
            # 3. ì „ì²´ ì´ìƒë„ ì ìˆ˜
            overall_anomaly_score = np.mean(anomaly_scores)
            max_anomaly_score = np.max(anomaly_scores)
            
            # 4. ì´ìƒ íŒ¨ì¹˜ ì‹ë³„ (ìƒìœ„ 10%)
            threshold = np.percentile(anomaly_scores, 90)
            anomaly_patches = []
            
            for i, (pos, score) in enumerate(zip(positions, anomaly_scores)):
                if score > threshold:
                    anomaly_patches.append({
                        'position': [int(pos[0]), int(pos[1]), int(pos[2]), int(pos[3])],  # tupleì„ listë¡œ ë³€í™˜
                        'score': float(score),
                        'patch_index': int(i)
                    })
            
            # 5. íŒ¨ì¹˜ ê¸°ë°˜ íˆíŠ¸ë§µ ìƒì„±
            patch_heatmap = self.generate_heatmap(image, patches, positions, anomaly_scores)
            
            # 6. Grad-CAM ìƒì„± (ì•ˆì „í•œ ë²„ì „)
            try:
                gradcam_heatmap = self.generate_gradcam_for_image(image)
                logger.info("âœ… Grad-CAM ìƒì„± ì„±ê³µ")
            except Exception as gradcam_error:
                logger.warning(f"Grad-CAM ìƒì„± ì‹¤íŒ¨, íŒ¨ì¹˜ íˆíŠ¸ë§µ ì‚¬ìš©: {gradcam_error}")
                gradcam_heatmap = patch_heatmap
            
            # 7. íˆíŠ¸ë§µ ì˜¤ë²„ë ˆì´ ìƒì„±
            overlay_image = self._create_overlay(image, gradcam_heatmap)
            
            # 8. Base64 ì¸ì½”ë”©
            overlay_base64 = self._encode_image_to_base64(overlay_image)
            
            logger.info(f"âœ… ë¶„ì„ ì™„ë£Œ: ì´ìƒë„={overall_anomaly_score:.3f}, ì´ìƒíŒ¨ì¹˜={len(anomaly_patches)}ê°œ")
            
            # ğŸ”¥ JSON ì§ë ¬í™” ì•ˆì „ ê²°ê³¼ ë°˜í™˜
            return {
                'status': 'success',
                'results': {
                    'overall_anomaly_score': float(overall_anomaly_score),  # numpy floatì„ Python floatìœ¼ë¡œ ë³€í™˜
                    'max_anomaly_score': float(max_anomaly_score),
                    'num_patches': int(len(patches)),  # ëª…ì‹œì  int ë³€í™˜
                    'num_anomaly_patches': int(len(anomaly_patches)),
                    'anomaly_patches': anomaly_patches,  # ì´ë¯¸ ì•ˆì „í•˜ê²Œ ë³€í™˜ë¨
                    'threshold': float(threshold),
                    'is_abnormal': bool(overall_anomaly_score > 0.5),  # numpy boolì„ Python boolë¡œ ë³€í™˜
                    'confidence': float(min(overall_anomaly_score * 100, 100)),
                    'heatmap_overlay': f"data:image/png;base64,{overlay_base64}",
                    'image_size': [int(image.shape[0]), int(image.shape[1])]  # tupleì„ listë¡œ ë³€í™˜
                },
                'timestamp': datetime.now().isoformat()
            }
            
        except Exception as e:
            logger.error(f"âŒ ì´ë¯¸ì§€ ë¶„ì„ ì‹¤íŒ¨: {e}")
            logger.exception("ìƒì„¸ ì˜¤ë¥˜:")
            return {
                'status': 'error',
                'message': str(e)
            }
    
    def _create_overlay(self, original_image: np.ndarray, heatmap: np.ndarray) -> np.ndarray:
        """ì›ë³¸ ì´ë¯¸ì§€ì— íˆíŠ¸ë§µ ì˜¤ë²„ë ˆì´"""
        try:
            # íˆíŠ¸ë§µ ì •ê·œí™”
            heatmap_normalized = ((heatmap - heatmap.min()) / (heatmap.max() - heatmap.min()) * 255).astype(np.uint8)
            
            # ì»¬ëŸ¬ë§µ ì ìš©
            heatmap_colored = cv2.applyColorMap(heatmap_normalized, cv2.COLORMAP_JET)
            
            # ì›ë³¸ ì´ë¯¸ì§€ ì¤€ë¹„
            if len(original_image.shape) == 2:
                original_rgb = cv2.cvtColor(original_image, cv2.COLOR_GRAY2RGB)
            else:
                original_rgb = original_image
            
            # ì˜¤ë²„ë ˆì´ (70% ì›ë³¸ + 30% íˆíŠ¸ë§µ)
            overlay = cv2.addWeighted(original_rgb, 0.7, heatmap_colored, 0.3, 0)
            
            return overlay
            
        except Exception as e:
            logger.error(f"ì˜¤ë²„ë ˆì´ ìƒì„± ì˜¤ë¥˜: {e}")
            # Fallback: ì›ë³¸ ì´ë¯¸ì§€ ë°˜í™˜
            if len(original_image.shape) == 2:
                return cv2.cvtColor(original_image, cv2.COLOR_GRAY2RGB)
            else:
                return original_image
    
    def _encode_image_to_base64(self, image: np.ndarray) -> str:
        """ì´ë¯¸ì§€ë¥¼ Base64ë¡œ ì¸ì½”ë”©"""
        try:
            _, buffer = cv2.imencode('.png', image)
            return base64.b64encode(buffer).decode('utf-8')
        except Exception as e:
            logger.error(f"Base64 ì¸ì½”ë”© ì˜¤ë¥˜: {e}")
            return ""

# Django ì„œë¹„ìŠ¤ ë˜í¼ (ë³€ê²½ì‚¬í•­ ì—†ìŒ)
class SimCLRInferenceService:
    """Djangoìš© SimCLR ì¶”ë¡  ì„œë¹„ìŠ¤"""
    
    def __init__(self):
        self.inference = None
        self.model_loaded = False
        
        # ëª¨ë¸ íŒŒì¼ ê²½ë¡œ
        self.model_path = Path("ai_models/sim_patch/final_efficientnet_simclr.pth")
        self.features_path = Path("ai_models/sim_patch/patch_features.pkl")
        
        self._initialize()
    
    def _initialize(self):
        """ì„œë¹„ìŠ¤ ì´ˆê¸°í™”"""
        try:
            if self.model_path.exists() and self.features_path.exists():
                device = 'cuda' if torch.cuda.is_available() else 'cpu'
                logger.info(f"ğŸ”„ SimCLR ëª¨ë¸ ë¡œë”© ì‹œì‘... (device: {device})")
                
                self.inference = SimCLRPatchInference(
                    str(self.model_path), 
                    str(self.features_path), 
                    device
                )
                self.model_loaded = True
                logger.info("âœ… SimCLR ì¶”ë¡  ì„œë¹„ìŠ¤ ì´ˆê¸°í™” ì™„ë£Œ")
            else:
                logger.warning(f"âš ï¸ SimCLR ëª¨ë¸ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. ëª¨ë¸: {self.model_path.exists()}, íŠ¹ì§•: {self.features_path.exists()}")
                
        except Exception as e:
            logger.error(f"âŒ SimCLR ì„œë¹„ìŠ¤ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            logger.exception("ìƒì„¸ ì˜¤ë¥˜:")
    
    def analyze_dicom_image(self, image_array: np.ndarray, study_uid: str) -> Dict:
        """DICOM ì´ë¯¸ì§€ ë¶„ì„"""
        if not self.model_loaded or self.inference is None:
            return {
                'status': 'error',
                'message': 'SimCLR ëª¨ë¸ì´ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.'
            }
        
        try:
            result = self.inference.analyze_image(image_array)
            
            # ì¶”ê°€ ë©”íƒ€ë°ì´í„°
            if result['status'] == 'success':
                result['study_uid'] = study_uid
                result['analysis_type'] = 'simclr_patch_based'
                result['model_type'] = 'EfficientNet-B2 SimCLR (Fixed Gradient)'
            
            return result
            
        except Exception as e:
            logger.error(f"âŒ DICOM ì´ë¯¸ì§€ ë¶„ì„ ì‹¤íŒ¨: {e}")
            return {
                'status': 'error',
                'message': str(e)
            }
    
    def get_model_status(self) -> Dict:
        """ëª¨ë¸ ìƒíƒœ ë°˜í™˜"""
        return {
            'loaded': self.model_loaded,
            'model_path_exists': self.model_path.exists(),
            'features_path_exists': self.features_path.exists(),
            'device': self.inference.device if self.inference else 'unknown'
        }

# ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤
simclr_inference_service = SimCLRInferenceService()