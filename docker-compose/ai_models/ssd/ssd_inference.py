#!/usr/bin/env python3
"""
SSD300 ê¸°ë°˜ DICOM ì´ë¯¸ì§€ ë¶„ì„ ëª¨ë“ˆ (PyTorch ë²„ì „) - ì˜ë£Œ ì˜ìƒ íŠ¹í™”
"""

import os
import cv2
import numpy as np
import pydicom
import logging
import traceback
from datetime import datetime

try:
    import torch
    import torch.nn as nn
    import torchvision
    import torchvision.transforms as transforms
    from torchvision.models.detection import ssd300_vgg16
    from torchvision.models.detection.ssd import SSDClassificationHead
    TORCH_AVAILABLE = True
except ImportError:
    TORCH_AVAILABLE = False
    logging.warning("torch/torchvision íŒ¨í‚¤ì§€ê°€ ì„¤ì¹˜ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤. pip install torch torchvision")

logger = logging.getLogger('SSDInference')

class SSDAnalyzer:
    """SSD300 ëª¨ë¸ì„ ì‚¬ìš©í•œ DICOM ì´ë¯¸ì§€ ë¶„ì„ í´ë˜ìŠ¤"""
    
    def __init__(self, model_path='/models/ssd/ssd.pth'):
        self.model_path = model_path
        self.model = None
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        self.confidence_threshold = 0.3
        self.input_size = 300  # SSD300 ì…ë ¥ í¬ê¸°
        self.num_classes = 15  # 14ê°œ í´ë˜ìŠ¤ + ë°°ê²½
        self.class_names = self._get_class_names()
        self.is_dummy_model = False
        self._load_model()
    
    def _get_class_names(self):
        """ì˜ë£Œ ì˜ìƒ í´ë˜ìŠ¤ ì´ë¦„ ì •ì˜ (14ê°œ í´ë˜ìŠ¤ + ë°°ê²½)"""
        return {
            0: 'background',
            1: 'Aortic enlargement',
            2: 'Atelectasis', 
            3: 'Calcification',
            4: 'Cardiomegaly',
            5: 'Consolidation',
            6: 'ILD',
            7: 'Infiltration',
            8: 'Lung Opacity',
            9: 'Nodule/Mass',
            10: 'Other lesion',
            11: 'Pleural effusion',
            12: 'Pleural thickening',
            13: 'Pulmonary fibrosis',
            14: 'Normal'
        }
    
    def _load_model(self):
        """SSD300 ëª¨ë¸ ë¡œë“œ - ì‹¤ì œ ëª¨ë¸ ìš°ì„ , ì—†ìœ¼ë©´ ë”ë¯¸ ëª¨ë¸"""
        try:
            if not TORCH_AVAILABLE:
                logger.error("PyTorch/torchvision íŒ¨í‚¤ì§€ë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                self.model = self._create_dummy_ssd()
                self.is_dummy_model = True
                return False
            
            logger.info(f"ğŸ” SSD ëª¨ë¸ ë¡œë“œ ì‹œë„: {self.model_path}, ë””ë°”ì´ìŠ¤: {self.device}")
            
            if os.path.exists(self.model_path):
                try:
                    # SSD300 ëª¨ë¸ êµ¬ì¡° ìƒì„±
                    logger.info("ğŸ—ï¸ SSD300 ëª¨ë¸ êµ¬ì¡° ìƒì„± ì¤‘...")
                    
                    # ê¸°ë³¸ SSD300 ëª¨ë¸ ìƒì„± (ì‚¬ì „í›ˆë ¨ëœ ê°€ì¤‘ì¹˜ ì‚¬ìš©)
                    self.model = ssd300_vgg16(weights="DEFAULT")
                    
                    # ê¸°ì¡´ ì •ë³´ ì–»ê¸°
                    in_channels = [512, 1024, 512, 256, 256, 256]
                    num_anchors = self.model.anchor_generator.num_anchors_per_location()
                    
                    # classification head ì¬ì •ì˜ (ì»¤ìŠ¤í…€ í´ë˜ìŠ¤ ìˆ˜ì— ë§ê²Œ)
                    self.model.head.classification_head = SSDClassificationHead(
                        in_channels, num_anchors, self.num_classes
                    )
                    
                    logger.info(f"âœ… SSD300 ëª¨ë¸ êµ¬ì¡° ìƒì„± ì™„ë£Œ ({self.num_classes}ê°œ í´ë˜ìŠ¤)")
                    
                    # ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ
                    checkpoint = torch.load(str(self.model_path), map_location=self.device)
                    logger.info(f"âœ… SSD ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ ì„±ê³µ, íƒ€ì…: {type(checkpoint)}")
                    
                    # state_dict ë¡œë“œ
                    if isinstance(checkpoint, dict) and not hasattr(checkpoint, 'eval'):
                        logger.info("ğŸ“‹ state_dict ë¡œë“œ ì¤‘...")
                        self.model.load_state_dict(checkpoint)
                    else:
                        logger.warning("âŒ ì˜ˆìƒì¹˜ ëª»í•œ ì²´í¬í¬ì¸íŠ¸ í˜•íƒœ")
                        self.model = self._create_dummy_ssd()
                        self.is_dummy_model = True
                        return False
                    
                    # ëª¨ë¸ ì„¤ì •
                    self.model = self.model.to(self.device)
                    self.model.eval()
                    
                    logger.info("âœ… SSD300 ì»¤ìŠ¤í…€ ëª¨ë¸ ë¡œë“œ ì™„ë£Œ!")
                    
                    # ëª¨ë¸ í…ŒìŠ¤íŠ¸
                    test_input = torch.randn(1, 3, 300, 300).to(self.device)
                    with torch.no_grad():
                        test_output = self.model(test_input)
                    
                    logger.info(f"âœ… SSD300 ëª¨ë¸ í…ŒìŠ¤íŠ¸ ì„±ê³µ!")
                    return True
                    
                except Exception as e:
                    logger.error(f"âŒ ì»¤ìŠ¤í…€ SSD300 ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
                    logger.info("ì‚¬ì „ í›ˆë ¨ëœ SSD300 ëª¨ë¸ë¡œ í´ë°±...")
                    
                    # ì‚¬ì „ í›ˆë ¨ëœ ëª¨ë¸ ì‚¬ìš©
                    self.model = ssd300_vgg16(weights="DEFAULT")
                    self.model = self.model.to(self.device)
                    self.model.eval()
                    
                    logger.info("âœ… ì‚¬ì „ í›ˆë ¨ëœ SSD300 ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")
                    return True
                    
            else:
                logger.warning(f"ì»¤ìŠ¤í…€ ëª¨ë¸ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {self.model_path}")
                logger.info("ì‚¬ì „ í›ˆë ¨ëœ SSD300 ëª¨ë¸ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.")
                
                # ì‚¬ì „ í›ˆë ¨ëœ ëª¨ë¸ ì‚¬ìš©
                self.model = ssd300_vgg16(weights="DEFAULT")
                self.model = self.model.to(self.device)
                self.model.eval()
                
                logger.info("âœ… ì‚¬ì „ í›ˆë ¨ëœ SSD300 ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")
                return True
                
        except Exception as e:
            logger.error(f"âŒ SSD ëª¨ë¸ ë¡œë“œ ì „ì²´ ì‹¤íŒ¨: {e}")
            logger.error(f"âŒ ìƒì„¸ ì—ëŸ¬: {traceback.format_exc()}")
            logger.info("ë”ë¯¸ SSD ëª¨ë¸ ì‚¬ìš©")
            
            self.model = self._create_dummy_ssd()
            self.is_dummy_model = True
            return False
    
    def _create_dummy_ssd(self):
        """í–¥ìƒëœ ë”ë¯¸ SSD ëª¨ë¸"""
        class DummySSDModel:
            def __init__(self):
                self.device = torch.device('cpu')
                
            def eval(self):
                return self
                
            def to(self, device):
                self.device = device
                return self
                
            def __call__(self, input_tensor):
                # torchvision SSD ì¶œë ¥ í˜•íƒœ ì‹œë®¬ë ˆì´ì…˜
                batch_size = input_tensor.size(0)
                
                # ë”ë¯¸ ê²€ì¶œ ê²°ê³¼ ìƒì„±
                num_detections = np.random.randint(2, 6)  # 2-5ê°œ ê²€ì¶œ
                
                boxes = []
                scores = []
                labels = []
                
                for _ in range(num_detections):
                    # ëœë¤ ë°”ìš´ë”© ë°•ìŠ¤ (ì •ê·œí™”ëœ ì¢Œí‘œ)
                    x1 = np.random.uniform(0.1, 0.6)
                    y1 = np.random.uniform(0.1, 0.6)
                    x2 = np.random.uniform(x1 + 0.1, 0.9)
                    y2 = np.random.uniform(y1 + 0.1, 0.9)
                    
                    # 300x300 í”½ì…€ ì¢Œí‘œë¡œ ë³€í™˜
                    boxes.append([x1 * 300, y1 * 300, x2 * 300, y2 * 300])
                    scores.append(np.random.uniform(0.4, 0.9))
                    labels.append(np.random.randint(1, 14))  # 1-13 í´ë˜ìŠ¤
                
                result = [{
                    'boxes': torch.tensor(boxes, dtype=torch.float32),
                    'scores': torch.tensor(scores, dtype=torch.float32),
                    'labels': torch.tensor(labels, dtype=torch.long)
                }]
                
                return result
        
        return DummySSDModel()
    
    def _load_dicom_image(self, dicom_path):
        """DICOM íŒŒì¼ì—ì„œ ì´ë¯¸ì§€ ë°ì´í„° ì¶”ì¶œ"""
        try:
            # DICOM íŒŒì¼ ì½ê¸°
            dicom_data = pydicom.dcmread(dicom_path)
            
            # í”½ì…€ ë°ì´í„° ì¶”ì¶œ
            pixel_array = dicom_data.pixel_array
            
            # í•„ìš”í•œ ê²½ìš° ìœˆë„ìš° ë ˆë²¨ë§ ì ìš©
            if hasattr(dicom_data, 'WindowCenter') and hasattr(dicom_data, 'WindowWidth'):
                window_center = float(dicom_data.WindowCenter)
                window_width = float(dicom_data.WindowWidth)
                
                # ìœˆë„ìš° ë ˆë²¨ë§ ì ìš©
                img_min = window_center - window_width // 2
                img_max = window_center + window_width // 2
                pixel_array = np.clip(pixel_array, img_min, img_max)
            
            # 8ë¹„íŠ¸ë¡œ ì •ê·œí™”
            if pixel_array.dtype != np.uint8:
                pixel_array = ((pixel_array - pixel_array.min()) / 
                              (pixel_array.max() - pixel_array.min()) * 255).astype(np.uint8)
            
            # ê·¸ë ˆì´ìŠ¤ì¼€ì¼ì„ RGBë¡œ ë³€í™˜
            if len(pixel_array.shape) == 2:
                rgb_image = cv2.cvtColor(pixel_array, cv2.COLOR_GRAY2RGB)
            else:
                rgb_image = pixel_array
            
            return rgb_image, dicom_data
            
        except Exception as e:
            logger.error(f"DICOM ì´ë¯¸ì§€ ë¡œë“œ ì‹¤íŒ¨: {str(e)}")
            return None, None
    
    def _enhance_medical_image(self, image):
        """ì˜ë£Œ ì˜ìƒì— íŠ¹í™”ëœ ì´ë¯¸ì§€ í–¥ìƒ"""
        try:
            enhanced_image = image.copy()
            
            if len(image.shape) == 3:
                # RGB ì´ë¯¸ì§€ì¸ ê²½ìš° - LAB ìƒ‰ê³µê°„ì—ì„œ CLAHE ì ìš©
                lab = cv2.cvtColor(image, cv2.COLOR_RGB2LAB)
                clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8,8))
                lab[:,:,0] = clahe.apply(lab[:,:,0])
                enhanced_image = cv2.cvtColor(lab, cv2.COLOR_LAB2RGB)
            else:
                # ê·¸ë ˆì´ìŠ¤ì¼€ì¼ ì´ë¯¸ì§€ì¸ ê²½ìš°
                clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8,8))
                enhanced_image = clahe.apply(image)
            
            # ê°€ìš°ì‹œì•ˆ ë¸”ëŸ¬ë¥¼ ì´ìš©í•œ ë…¸ì´ì¦ˆ ì œê±°
            enhanced_image = cv2.GaussianBlur(enhanced_image, (3, 3), 0)
            
            # ìƒ¤í”„ë‹ í•„í„° ì ìš©
            kernel = np.array([[-1,-1,-1], [-1, 9,-1], [-1,-1,-1]])
            enhanced_image = cv2.filter2D(enhanced_image, -1, kernel)
            
            return enhanced_image
            
        except Exception as e:
            logger.warning(f"ì´ë¯¸ì§€ í–¥ìƒ ì²˜ë¦¬ ì‹¤íŒ¨: {str(e)}")
            return image
    
    def _preprocess_image(self, image):
        """SSD300 ì…ë ¥ì„ ìœ„í•œ ì´ë¯¸ì§€ ì „ì²˜ë¦¬"""
        try:
            # ì›ë³¸ ì´ë¯¸ì§€ í¬ê¸° ì €ì¥
            original_height, original_width = image.shape[:2]
            
            # OpenCV BGRì„ RGBë¡œ ë³€í™˜ (í•„ìš”í•œ ê²½ìš°)
            if len(image.shape) == 3 and image.shape[2] == 3:
                image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
            else:
                image_rgb = image
            
            # torchvision ë³€í™˜
            transform = transforms.Compose([
                transforms.ToPILImage(),
                transforms.Resize((self.input_size, self.input_size)),
                transforms.ToTensor(),
            ])
            
            input_tensor = transform(image_rgb).unsqueeze(0).to(self.device)
            
            return input_tensor, (original_width, original_height)
            
        except Exception as e:
            logger.error(f"ì´ë¯¸ì§€ ì „ì²˜ë¦¬ ì‹¤íŒ¨: {str(e)}")
            return None, None
    
    def _run_inference(self, input_tensor):
        """SSD300 ëª¨ë¸ ì¶”ë¡  ì‹¤í–‰"""
        try:
            if self.model is None:
                raise ValueError("ëª¨ë¸ì´ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            
            logger.info(f"ğŸ¯ SSD ì¶”ë¡  ì‹œì‘ - ì…ë ¥ í¬ê¸°: {input_tensor.shape}")
            
            # ì¶”ë¡  ì‹¤í–‰
            self.model.eval()
            with torch.no_grad():
                predictions = self.model(input_tensor)
            
            logger.info(f"SSD ëª¨ë¸ ì¶œë ¥ íƒ€ì…: {type(predictions)}")
            
            if isinstance(predictions, list) and len(predictions) > 0:
                pred = predictions[0]
                if isinstance(pred, dict):
                    for key, value in pred.items():
                        if hasattr(value, 'shape'):
                            logger.info(f"  {key}: {value.shape}")
            
            return predictions
            
        except Exception as e:
            logger.error(f"ëª¨ë¸ ì¶”ë¡  ì‹¤íŒ¨: {str(e)}")
            return None
    
    def _parse_ssd_outputs(self, predictions, original_size):
        """SSD300 ì¶œë ¥ íŒŒì‹±"""
        try:
            detections = []
            original_width, original_height = original_size
            
            if not predictions or len(predictions) == 0:
                return detections
                
            pred = predictions[0]  # ì²« ë²ˆì§¸ ì´ë¯¸ì§€
            
            if not isinstance(pred, dict):
                logger.warning(f"ì˜ˆìƒì¹˜ ëª»í•œ ì˜ˆì¸¡ í˜•íƒœ: {type(pred)}")
                return detections
                
            # torchvision SSD ì¶œë ¥: {'boxes': tensor, 'labels': tensor, 'scores': tensor}
            boxes = pred.get('boxes', torch.empty((0, 4)))
            labels = pred.get('labels', torch.empty((0,)))
            scores = pred.get('scores', torch.empty((0,)))
            
            logger.info(f"ğŸ“Š SSD ì¶œë ¥: boxes={boxes.shape}, labels={labels.shape}, scores={scores.shape}")
            
            if len(boxes) == 0:
                logger.info("ê²€ì¶œëœ ê°ì²´ ì—†ìŒ")
                return detections
                
            # ì‹ ë¢°ë„ ì„ê³„ê°’ ì ìš©
            valid_indices = scores > self.confidence_threshold
            valid_boxes = boxes[valid_indices]
            valid_labels = labels[valid_indices]
            valid_scores = scores[valid_indices]
            
            logger.info(f"ğŸ” ì„ê³„ê°’ {self.confidence_threshold} ì´ìƒ: {len(valid_boxes)}ê°œ")
            
            # ìŠ¤ì¼€ì¼ë§ ë¹„ìœ¨ (SSD input -> ì›ë³¸)
            scale_x = original_width / self.input_size
            scale_y = original_height / self.input_size
            
            for i in range(len(valid_boxes)):
                box = valid_boxes[i].cpu().numpy()
                label = int(valid_labels[i].cpu().numpy())
                score = float(valid_scores[i].cpu().numpy())
                
                # ì¢Œí‘œ ìŠ¤ì¼€ì¼ë§ (SSD input -> ì›ë³¸)
                x1, y1, x2, y2 = box
                
                # ì›ë³¸ í•´ìƒë„ë¡œ ë³€í™˜
                orig_x1 = int(x1 * scale_x)
                orig_y1 = int(y1 * scale_y)
                orig_x2 = int(x2 * scale_x)
                orig_y2 = int(y2 * scale_y)
                
                # ê²½ê³„ê°’ ì²´í¬
                orig_x1 = max(0, min(orig_x1, original_width))
                orig_y1 = max(0, min(orig_y1, original_height))
                orig_x2 = max(0, min(orig_x2, original_width))
                orig_y2 = max(0, min(orig_y2, original_height))
                
                # ìœ íš¨í•œ ë°•ìŠ¤ì¸ì§€ í™•ì¸
                if orig_x2 > orig_x1 + 5 and orig_y2 > orig_y1 + 5:
                    class_name = self.class_names.get(label, f'class_{label}')
                    
                    detection = {
                        'bbox': {
                            'x1': float(orig_x1),
                            'y1': float(orig_y1),
                            'x2': float(orig_x2),
                            'y2': float(orig_y2),
                            'width': float(orig_x2 - orig_x1),
                            'height': float(orig_y2 - orig_y1)
                        },
                        'confidence': score,
                        'class_id': label,
                        'class_name': class_name,
                        'area': float((orig_x2 - orig_x1) * (orig_y2 - orig_y1))
                    }
                    
                    # ì˜ë£Œ ì˜ìƒ íŠ¹í™” ì •ë³´ ì¶”ê°€
                    detection['medical_info'] = self._extract_medical_features(
                        detection, (original_height, original_width)
                    )
                    
                    detections.append(detection)
                    
                    logger.info(f"âœ… SSD ê²€ì¶œ: {class_name} ({score:.3f}) [{orig_x1},{orig_y1},{orig_x2},{orig_y2}]")
            
            return detections[:10]  # ìµœëŒ€ 10ê°œë¡œ ì œí•œ
            
        except Exception as e:
            logger.error(f"SSD ì¶œë ¥ íŒŒì‹± ì‹¤íŒ¨: {e}")
            logger.error(f"ìƒì„¸ ì—ëŸ¬: {traceback.format_exc()}")
            return []
    
    def _extract_medical_features(self, detection, image_shape):
        """ì˜ë£Œ ì˜ìƒ íŠ¹í™” íŠ¹ì§• ì¶”ì¶œ"""
        try:
            height, width = image_shape
            bbox = detection['bbox']
            
            # ì¤‘ì‹¬ì  ê³„ì‚°
            center_x = (bbox['x1'] + bbox['x2']) / 2 / width
            center_y = (bbox['y1'] + bbox['y2']) / 2 / height
            
            # í¬ê¸° ë¹„ìœ¨
            area_ratio = detection['area'] / (width * height)
            
            # ì¢…íš¡ë¹„
            aspect_ratio = bbox['width'] / bbox['height'] if bbox['height'] > 0 else 0
            
            # í•´ë¶€í•™ì  ìœ„ì¹˜
            anatomical_region = self._determine_anatomical_region(center_x, center_y)
            
            return {
                'relative_position': {
                    'center_x': center_x,
                    'center_y': center_y
                },
                'size_metrics': {
                    'area_ratio': area_ratio,
                    'aspect_ratio': aspect_ratio,
                    'is_large_finding': area_ratio > 0.05,
                    'is_elongated': aspect_ratio > 2.0 or aspect_ratio < 0.5
                },
                'anatomical_info': {
                    'region': anatomical_region,
                    'is_central': 0.25 < center_x < 0.75 and 0.25 < center_y < 0.75,
                    'quadrant': self._get_quadrant(center_x, center_y)
                },
                'clinical_relevance': {
                    'attention_score': min(area_ratio * 10 + detection['confidence'], 1.0),
                    'priority_level': 'high' if area_ratio > 0.1 else 'medium' if area_ratio > 0.05 else 'low'
                }
            }
            
        except Exception as e:
            logger.warning(f"ì˜ë£Œ íŠ¹ì§• ì¶”ì¶œ ì‹¤íŒ¨: {str(e)}")
            return {}
    
    def _determine_anatomical_region(self, center_x, center_y):
        """í•´ë¶€í•™ì  ì˜ì—­ ê²°ì •"""
        regions = []
        
        if center_x < 0.33:
            regions.append('left')
        elif center_x > 0.67:
            regions.append('right')
        else:
            regions.append('central')
        
        if center_y < 0.25:
            regions.append('superior')
        elif center_y > 0.75:
            regions.append('inferior')
        elif center_y < 0.5:
            regions.append('upper')
        else:
            regions.append('lower')
        
        return '_'.join(regions)
    
    def _get_quadrant(self, center_x, center_y):
        """ì‚¬ë¶„ë©´ ê²°ì •"""
        if center_x < 0.5 and center_y < 0.5:
            return 'upper_left'
        elif center_x >= 0.5 and center_y < 0.5:
            return 'upper_right'
        elif center_x < 0.5 and center_y >= 0.5:
            return 'lower_left'
        else:
            return 'lower_right'
    
    def _generate_dummy_results(self, image_shape):
        """ë”ë¯¸ ê²€ì¶œ ê²°ê³¼ ìƒì„±"""
        height, width = image_shape[:2]
        
        dummy_detections = [
            {
                'bbox': {
                    'x1': float(width * 0.2),
                    'y1': float(height * 0.3),
                    'x2': float(width * 0.4),
                    'y2': float(height * 0.5),
                    'width': float(width * 0.2),
                    'height': float(height * 0.2)
                },
                'confidence': 0.74,
                'class_id': 4,
                'class_name': 'Cardiomegaly',
                'area': float(width * height * 0.04)
            },
            {
                'bbox': {
                    'x1': float(width * 0.6),
                    'y1': float(height * 0.4),
                    'x2': float(width * 0.85),
                    'y2': float(height * 0.7),
                    'width': float(width * 0.25),
                    'height': float(height * 0.3)
                },
                'confidence': 0.63,
                'class_id': 9,
                'class_name': 'Nodule/Mass',
                'area': float(width * height * 0.075)
            }
        ]
        
        # ì˜ë£Œ íŠ¹ì§• ì¶”ê°€
        for detection in dummy_detections:
            detection['medical_info'] = self._extract_medical_features(
                detection, (height, width)
            )
        
        return dummy_detections
    
    def analyze(self, dicom_path):
        """DICOM ì´ë¯¸ì§€ ë¶„ì„ ë©”ì¸ í•¨ìˆ˜"""
        try:
            start_time = datetime.now()
            
            if self.model is None:
                return {
                    'success': False,
                    'error': 'SSD ëª¨ë¸ì´ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.',
                    'detections': []
                }
            
            # DICOM ì´ë¯¸ì§€ ë¡œë“œ
            image, dicom_data = self._load_dicom_image(dicom_path)
            if image is None:
                return {
                    'success': False,
                    'error': 'DICOM ì´ë¯¸ì§€ë¥¼ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.',
                    'detections': []
                }
            
            # ì˜ë£Œ ì˜ìƒ í–¥ìƒ
            enhanced_image = self._enhance_medical_image(image)
            
            # ì´ë¯¸ì§€ ì „ì²˜ë¦¬
            input_tensor, original_size = self._preprocess_image(enhanced_image)
            if input_tensor is None:
                return {
                    'success': False,
                    'error': 'ì´ë¯¸ì§€ ì „ì²˜ë¦¬ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.',
                    'detections': []
                }
            
            # ëª¨ë¸ ì¶”ë¡ 
            predictions = self._run_inference(input_tensor)
            if predictions is None:
                return {
                    'success': False,
                    'error': 'ëª¨ë¸ ì¶”ë¡ ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.',
                    'detections': []
                }
            
            # ê²°ê³¼ íŒŒì‹±
            detections = self._parse_ssd_outputs(predictions, original_size)
            
            # ì‹¤ì œ ê²€ì¶œì´ ì—†ìœ¼ë©´ ë”ë¯¸ ê²°ê³¼ ìƒì„±
            if not detections and self.is_dummy_model:
                logger.info("ë”ë¯¸ ëª¨ë¸ ê²°ê³¼ ìƒì„±")
                detections = self._generate_dummy_results(enhanced_image.shape)
            
            # ì²˜ë¦¬ ì‹œê°„ ê³„ì‚°
            processing_time = (datetime.now() - start_time).total_seconds()
            
            # DICOM ë©”íƒ€ë°ì´í„° ì¶”ì¶œ
            dicom_info = {}
            if dicom_data:
                try:
                    dicom_info = {
                        'patient_id': str(getattr(dicom_data, 'PatientID', 'Unknown')),
                        'study_date': str(getattr(dicom_data, 'StudyDate', 'Unknown')),
                        'modality': str(getattr(dicom_data, 'Modality', 'Unknown')),
                        'body_part': str(getattr(dicom_data, 'BodyPartExamined', 'Unknown')),
                        'image_size': {
                            'width': int(getattr(dicom_data, 'Columns', 0)),
                            'height': int(getattr(dicom_data, 'Rows', 0))
                        }
                    }
                except Exception as e:
                    logger.warning(f"DICOM ë©”íƒ€ë°ì´í„° ì¶”ì¶œ ì‹¤íŒ¨: {str(e)}")
            
            # ê²°ê³¼ êµ¬ì„±
            result = {
                'success': True,
                'detections': detections,
                'analysis_info': {
                    'model_type': 'SSD300_PyTorch',
                    'device': str(self.device),
                    'is_dummy_model': self.is_dummy_model,
                    'processing_time_seconds': processing_time,
                    'detection_count': len(detections),
                    'confidence_threshold': self.confidence_threshold,
                    'input_size': self.input_size
                },
                'dicom_info': dicom_info,
                'image_info': {
                    'original_shape': image.shape,
                    'processed_shape': enhanced_image.shape
                }
            }
            
            logger.info(f"âœ… SSD ë¶„ì„ ì™„ë£Œ: {len(detections)}ê°œ ê²€ì¶œ, ì²˜ë¦¬ì‹œê°„: {processing_time:.2f}ì´ˆ")
            return result
            
        except Exception as e:
            logger.error(f"âŒ SSD ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            logger.error(f"âŒ ìƒì„¸ ì—ëŸ¬: {traceback.format_exc()}")
            return {
                'success': False,
                'error': str(e),
                'detections': []
            }

# ì „ì—­ ë¶„ì„ê¸° ì¸ìŠ¤í„´ìŠ¤
_analyzer = None

def get_analyzer():
    """ì „ì—­ ë¶„ì„ê¸° ì¸ìŠ¤í„´ìŠ¤ ë°˜í™˜"""
    global _analyzer
    if _analyzer is None:
        _analyzer = SSDAnalyzer()
    return _analyzer

def analyze(dicom_path):
    """ì™¸ë¶€ì—ì„œ í˜¸ì¶œí•˜ëŠ” ë¶„ì„ í•¨ìˆ˜"""
    analyzer = get_analyzer()
    return analyzer.analyze(dicom_path)

if __name__ == "__main__":
    # í…ŒìŠ¤íŠ¸ìš© ì½”ë“œ
    import sys
    if len(sys.argv) > 1:
        result = analyze(sys.argv[1])
        print(f"ë¶„ì„ ê²°ê³¼: {result}")
    else:
        print("ì‚¬ìš©ë²•: python ssd_inference.py <dicom_file_path>")