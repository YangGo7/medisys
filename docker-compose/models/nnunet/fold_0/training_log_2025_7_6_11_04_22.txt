
#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################
 
2025-07-06 11:04:23.128211: do_dummy_2d_data_aug: False 
2025-07-06 11:04:23.139213: Using splits from existing split file: C:\Users\chaey\Downloads\nnUNet_preprocessed\Dataset002_LUNA16\splits_final.json 
2025-07-06 11:04:23.150214: The split file contains 1 splits. 
2025-07-06 11:04:23.156211: Desired fold for training: 0 
2025-07-06 11:04:23.160211: This split has 147 training and 37 validation cases. 

This is the configuration used by this training:
Configuration name: 3d_fullres
 {'data_identifier': 'nnUNetPlans_3d_fullres', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 2, 'patch_size': [80, 192, 160], 'median_image_size_in_voxels': [253.0, 512.0, 512.0], 'spacing': [1.25, 0.703125, 0.703125], 'normalization_schemes': ['CTNormalization'], 'use_mask_for_norm': [False], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 6, 'features_per_stage': [32, 64, 128, 256, 320, 320], 'conv_op': 'torch.nn.modules.conv.Conv3d', 'kernel_sizes': [[3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]], 'strides': [[1, 1, 1], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [1, 2, 2]], 'n_conv_per_stage': [2, 2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2, 2], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm3d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': True, 'num_epochs': 300} 
 
These are the global plan.json settings:
 {'dataset_name': 'Dataset002_LUNA16', 'plans_name': 'nnUNetPlans', 'original_median_spacing_after_transp': [1.25, 0.703125, 0.703125], 'original_median_shape_after_transp': [246, 512, 512], 'image_reader_writer': 'SimpleITKIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 2487.0, 'mean': -470.8146667480469, 'median': -632.0, 'min': -1024.0, 'percentile_00_5': -1017.0, 'percentile_99_5': 1551.0, 'std': 437.6632080078125}}} 
 
2025-07-06 11:04:41.894473: Unable to plot network architecture: 
2025-07-06 11:04:41.907475: No module named 'hiddenlayer' 
2025-07-06 11:04:41.982473:  
2025-07-06 11:04:41.996473: Epoch 0 
2025-07-06 11:04:42.009474: Current learning rate: 0.01 
2025-07-06 11:32:09.664938: train_loss 0.0294 
2025-07-06 11:32:09.676939: val_loss -0.0224 
2025-07-06 11:32:09.681938: Pseudo dice [0.0] 
2025-07-06 11:32:09.686939: Epoch time: 1647.68 s 
2025-07-06 11:32:09.691938: Yayy! New best EMA pseudo Dice: 0.0 
2025-07-06 11:32:10.637598:  
2025-07-06 11:32:10.645599: Epoch 1 
2025-07-06 11:32:10.651600: Current learning rate: 0.00999 
2025-07-06 11:44:42.330979: train_loss -0.0158 
2025-07-06 11:44:42.345841: val_loss -0.0155 
2025-07-06 11:44:42.355842: Pseudo dice [0.0] 
2025-07-06 11:44:42.365841: Epoch time: 751.69 s 
2025-07-06 11:44:43.152848:  
2025-07-06 11:44:43.167847: Epoch 2 
2025-07-06 11:44:43.180848: Current learning rate: 0.00998 
2025-07-06 11:56:36.804992: train_loss -0.0233 
2025-07-06 11:56:36.813992: val_loss -0.0338 
2025-07-06 11:56:36.819992: Pseudo dice [0.0] 
2025-07-06 11:56:36.827993: Epoch time: 713.65 s 
2025-07-06 11:56:37.567998:  
2025-07-06 11:56:37.574998: Epoch 3 
2025-07-06 11:56:37.579998: Current learning rate: 0.00997 
2025-07-06 12:20:33.201331: train_loss -0.0682 
2025-07-06 12:20:33.212332: val_loss -0.1456 
2025-07-06 12:20:33.218331: Pseudo dice [0.0] 
2025-07-06 12:20:33.224331: Epoch time: 1435.63 s 
2025-07-06 12:20:33.924164:  
2025-07-06 12:20:33.932162: Epoch 4 
2025-07-06 12:20:33.938162: Current learning rate: 0.00996 
2025-07-06 12:43:04.666147: train_loss -0.207 
2025-07-06 12:43:04.666147: val_loss -0.338 
2025-07-06 12:43:04.677148: Pseudo dice [0.3539] 
2025-07-06 12:43:04.684148: Epoch time: 1350.74 s 
2025-07-06 12:43:04.690148: Yayy! New best EMA pseudo Dice: 0.0354 
2025-07-06 12:43:06.223975:  
2025-07-06 12:43:06.230975: Epoch 5 
2025-07-06 12:43:06.237975: Current learning rate: 0.00995 
2025-07-06 12:59:07.699281: train_loss -0.3352 
2025-07-06 12:59:07.711280: val_loss -0.3497 
2025-07-06 12:59:07.719280: Pseudo dice [0.3558] 
2025-07-06 12:59:07.724281: Epoch time: 961.48 s 
2025-07-06 12:59:07.728281: Yayy! New best EMA pseudo Dice: 0.0674 
2025-07-06 12:59:08.651287:  
2025-07-06 12:59:08.658286: Epoch 6 
2025-07-06 12:59:08.663287: Current learning rate: 0.00995 
2025-07-06 13:12:49.651926: train_loss -0.3511 
2025-07-06 13:12:49.662926: val_loss -0.34 
2025-07-06 13:12:49.668926: Pseudo dice [0.3206] 
2025-07-06 13:12:49.673925: Epoch time: 821.0 s 
2025-07-06 13:12:49.678925: Yayy! New best EMA pseudo Dice: 0.0927 
2025-07-06 13:12:50.618932:  
2025-07-06 13:12:50.630932: Epoch 7 
2025-07-06 13:12:50.640932: Current learning rate: 0.00994 
2025-07-06 13:25:36.260164: train_loss -0.3909 
2025-07-06 13:25:36.270164: val_loss -0.4151 
2025-07-06 13:25:36.275165: Pseudo dice [0.4004] 
2025-07-06 13:25:36.280165: Epoch time: 765.64 s 
2025-07-06 13:25:36.284165: Yayy! New best EMA pseudo Dice: 0.1235 
2025-07-06 13:25:37.215673:  
2025-07-06 13:25:37.222672: Epoch 8 
2025-07-06 13:25:37.228673: Current learning rate: 0.00993 
2025-07-06 13:59:07.006485: train_loss -0.407 
2025-07-06 13:59:07.007485: val_loss -0.3895 
2025-07-06 13:59:07.020486: Pseudo dice [0.3961] 
2025-07-06 13:59:07.030487: Epoch time: 2009.79 s 
2025-07-06 13:59:07.039486: Yayy! New best EMA pseudo Dice: 0.1508 
2025-07-06 13:59:08.544647:  
2025-07-06 13:59:08.560649: Epoch 9 
2025-07-06 13:59:08.574651: Current learning rate: 0.00992 
2025-07-06 14:16:54.997621: train_loss -0.4158 
2025-07-06 14:16:55.006036: val_loss -0.3876 
2025-07-06 14:16:55.013036: Pseudo dice [0.4137] 
2025-07-06 14:16:55.018036: Epoch time: 1066.45 s 
2025-07-06 14:16:55.023037: Yayy! New best EMA pseudo Dice: 0.1771 
2025-07-06 14:16:55.888231:  
2025-07-06 14:16:55.898231: Epoch 10 
2025-07-06 14:16:55.906231: Current learning rate: 0.00991 
