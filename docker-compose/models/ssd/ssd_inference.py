#!/usr/bin/env python3
"""
SSD300 ê¸°ë°˜ DICOM ì´ë¯¸ì§€ ë¶„ì„ ëª¨ë“ˆ (PyTorch ë²„ì „) - ì˜ë£Œ ì˜ìƒ íŠ¹í™” + í•„í„°ë§
"""

import os
import cv2
import numpy as np
import pydicom
import logging
import traceback
from datetime import datetime
import io
import sys # sys ëª¨ë“ˆ ì„í¬íŠ¸ ì¶”ê°€ (ë¡œê¹… í•¸ë“¤ëŸ¬ì—ì„œ ì‚¬ìš©)

try:
    import torch
    import torch.nn as nn
    import torchvision
    import torchvision.transforms as transforms
    from torchvision.models.detection import ssd300_vgg16
    from torchvision.models.detection.ssd import SSDClassificationHead
    TORCH_AVAILABLE = True
except ImportError:
    TORCH_AVAILABLE = False
    logging.warning("torch/torchvision íŒ¨í‚¤ì§€ê°€ ì„¤ì¹˜ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤. pip install torch torchvision")

logger = logging.getLogger('SSDInference')
# SSDInference ë¡œê±°ì— StreamHandler ì¶”ê°€ ë° ì¸ì½”ë”© ì„¤ì •
if not logger.handlers: 
    log_formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
    stream_handler = logging.StreamHandler(sys.stdout)
    stream_handler.setFormatter(log_formatter)
    stream_handler.encoding = 'utf-8' # <-- ì¸ì½”ë”© ì„¤ì •
    logger.addHandler(stream_handler)
    logger.setLevel(logging.INFO) # DEBUGë¡œ ì„¤ì •í•˜ë©´ ë”ë¯¸ ëª¨ë¸ ê²°ê³¼ ìƒì„± ê³¼ì •ë„ ë³¼ ìˆ˜ ìˆìŒ


class SSDAnalyzer:
    """SSD300 ëª¨ë¸ì„ ì‚¬ìš©í•œ DICOM ì´ë¯¸ì§€ ë¶„ì„ í´ë˜ìŠ¤"""
    
    def __init__(self, model_path='/models/ssd/ssd.pth'):
        self.model_path = model_path
        self.model = None
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        self.confidence_threshold = 0.1  # ğŸ”¥ ë‚®ì€ ì„ê³„ê°’ìœ¼ë¡œ ë³€ê²½ (í•„í„°ë§ì—ì„œ ì²˜ë¦¬)
        self.input_size = 300  # SSD300 ì…ë ¥ í¬ê¸°
        
        # ai_serviceì˜ MEDICAL_CLASSESì™€ ë™ì¼í•˜ê²Œ 14ê°œ í´ë˜ìŠ¤ (ë°°ê²½ ì œì™¸, ID 0ë¶€í„° 13ê¹Œì§€)
        self.num_classes = 14 
        self.class_names = self._get_class_names()

        self._load_model()
    
    def _get_class_names(self):
        """ì˜ë£Œ ì˜ìƒ í´ë˜ìŠ¤ ì´ë¦„ ì •ì˜ (ai_serviceì™€ ë™ì¼í•œ 14ê°œ í´ë˜ìŠ¤)"""
        return {
            0: 'Aortic enlargement',
            1: 'Atelectasis',
            2: 'Calcification',
            3: 'Cardiomegaly',
            4: 'Consolidation',
            5: 'ILD',
            6: 'Infiltration',
            7: 'Lung Opacity',
            8: 'Nodule/Mass',
            9: 'Other lesion',
            10: 'Pleural effusion',
            11: 'Pleural thickening',
            12: 'Pulmonary fibrosis',
            13: 'Normal'
        }
    
    def _load_model(self):
        """SSD300 ëª¨ë¸ ë¡œë“œ"""
        try:
            if not TORCH_AVAILABLE:
                logger.error("PyTorch/torchvision íŒ¨í‚¤ì§€ë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                return False
            
            logger.info(f"ğŸ” SSD300 ëª¨ë¸ ë¡œë“œ ì‹œë„: {self.model_path}")
            

            
            try:
                # ì»¤ìŠ¤í…€ ëª¨ë¸ ë¡œë“œ
                logger.info("ğŸ—ï¸ SSD300 ëª¨ë¸ êµ¬ì¡° ìƒì„± ì¤‘...")
                
                # ê¸°ë³¸ SSD300 ëª¨ë¸ ìƒì„± (weightsëŠ” torchvision 0.13.0+ì—ì„œ ENUM ì‚¬ìš© ê¶Œì¥)
                self.model = ssd300_vgg16(weights=torchvision.models.detection.SSD300_VGG16_Weights.DEFAULT)
                
                # ê¸°ì¡´ ì •ë³´ ì–»ê¸°
                in_channels = [512, 1024, 512, 256, 256, 256] 
                num_anchors = self.model.anchor_generator.num_anchors_per_location()
                
                # classification head ì¬ì •ì˜ (ì»¤ìŠ¤í…€ í´ë˜ìŠ¤ ìˆ˜ì— ë§ê²Œ)
                self.model.head.classification_head = SSDClassificationHead(
                    in_channels, num_anchors, self.num_classes
                )
                
                # ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ
                checkpoint = torch.load(str(self.model_path), map_location=self.device)
                
                # ì²´í¬í¬ì¸íŠ¸ê°€ state_dictë¥¼ í¬í•¨í•˜ëŠ” ë”•ì…”ë„ˆë¦¬ í˜•íƒœì¸ì§€ í™•ì¸í•˜ì—¬ ë¡œë“œ
                if isinstance(checkpoint, dict) and 'state_dict' in checkpoint:
                     self.model.load_state_dict(checkpoint['state_dict'])
                     logger.info("âœ… ì²´í¬í¬ì¸íŠ¸ (state_dict í‚¤ í¬í•¨) ë¡œë“œ ì„±ê³µ!")
                elif isinstance(checkpoint, dict): # state_dictë§Œ ì§ì ‘ ì €ì¥ëœ ê²½ìš°
                     self.model.load_state_dict(checkpoint)
                     logger.info("âœ… ì²´í¬í¬ì¸íŠ¸ (state_dict ì§ì ‘) ë¡œë“œ ì„±ê³µ!")
                else: # ê¸°íƒ€ ì˜ˆìƒì¹˜ ëª»í•œ í˜•íƒœ
                    logger.warning("âŒ ì˜ˆìƒì¹˜ ëª»í•œ ì²´í¬í¬ì¸íŠ¸ í˜•íƒœ.")
                    return False
                
                # ëª¨ë¸ ì„¤ì •
                self.model = self.model.to(self.device)
                self.model.eval()
                
                logger.info(f"âœ… SSD300 ì»¤ìŠ¤í…€ ëª¨ë¸ ë¡œë“œ ì™„ë£Œ: {self.model_path}")
                
                # ëª¨ë¸ ì •ë³´ ë¡œê¹…
                logger.info(f"ë¡œë“œëœ ëª¨ë¸ í´ë˜ìŠ¤ ìˆ˜: {self.num_classes}")
                logger.info(f"ë¡œë“œëœ ëª¨ë¸ í´ë˜ìŠ¤ë“¤: {list(self.class_names.values())}")
                
                
                return True
                
            except Exception as e:
                logger.error(f"âŒ ì»¤ìŠ¤í…€ SSD300 ëª¨ë¸ ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
                logger.error(f"ìƒì„¸ ì—ëŸ¬: {traceback.format_exc()}")

                return False
                
        except Exception as e: 
            logger.error(f"âŒ SSD ëª¨ë¸ ë¡œë“œ ìµœì¢… ì‹¤íŒ¨: {e}")
            logger.error(f"ìƒì„¸ ì—ëŸ¬: {traceback.format_exc()}")

            
            return False
    

    def _load_dicom_from_bytes(self, dicom_bytes):
        """ë°”ì´ë„ˆë¦¬ DICOM ë°ì´í„°ì—ì„œ ì´ë¯¸ì§€ ì¶”ì¶œ (Flask AI Service í˜¸í™˜)"""
        try:
            dicom_buffer = io.BytesIO(dicom_bytes)
            dicom_data = pydicom.dcmread(dicom_buffer)
            pixel_array = dicom_data.pixel_array
            
            if hasattr(dicom_data, 'WindowCenter') and hasattr(dicom_data, 'WindowWidth'):
                # WindowCenterì™€ WindowWidthê°€ MultiValueì¼ ìˆ˜ ìˆìœ¼ë¯€ë¡œ ì²« ë²ˆì§¸ ê°’ë§Œ ì‚¬ìš©
                window_center = float(dicom_data.WindowCenter[0] if isinstance(dicom_data.WindowCenter, pydicom.multival.MultiValue) else dicom_data.WindowCenter)
                window_width = float(dicom_data.WindowWidth[0] if isinstance(dicom_data.WindowWidth, pydicom.multival.MultiValue) else dicom_data.WindowWidth)
                
                img_min = window_center - window_width // 2
                img_max = window_center + window_width // 2
                pixel_array = np.clip(pixel_array, img_min, img_max)
            
            # 8ë¹„íŠ¸ ì •ê·œí™” (0~255 ë²”ìœ„ë¡œ ë³€í™˜)
            if pixel_array.dtype != np.uint8:
                if pixel_array.max() == pixel_array.min():
                    pixel_array = np.zeros_like(pixel_array, dtype=np.uint8)
                else:
                    pixel_array = ((pixel_array - pixel_array.min()) / 
                                 (pixel_array.max() - pixel_array.min()) * 255).astype(np.uint8)
            
            # ê·¸ë ˆì´ìŠ¤ì¼€ì¼ â†’ RGB ë³€í™˜
            if len(pixel_array.shape) == 2:
                rgb_image = cv2.cvtColor(pixel_array, cv2.COLOR_GRAY2RGB)
            else:
                rgb_image = pixel_array
            
            return rgb_image, dicom_data
            
        except Exception as e:
            logger.error(f"DICOM ì´ë¯¸ì§€ ë¡œë“œ ì‹¤íŒ¨: {str(e)}")
            logger.error(traceback.format_exc())
            return None, None
    
    
    def _enhance_medical_image(self, image):
        """ì˜ë£Œ ì˜ìƒì— íŠ¹í™”ëœ ì´ë¯¸ì§€ í–¥ìƒ"""
        try:
            enhanced_image = image.copy()
            
            # CLAHE ì ìš©
            if len(image.shape) == 3 and image.shape[2] == 3: # RGB ì´ë¯¸ì§€
                lab = cv2.cvtColor(image, cv2.COLOR_RGB2LAB)
                clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))
                lab[:,:,0] = clahe.apply(lab[:,:,0])
                enhanced_image = cv2.cvtColor(lab, cv2.COLOR_LAB2RGB)
            elif len(image.shape) == 2: # ê·¸ë ˆì´ìŠ¤ì¼€ì¼ ì´ë¯¸ì§€ (RGBë¡œ ë³€í™˜ í›„ CLAHE)
                temp_rgb = cv2.cvtColor(image, cv2.COLOR_GRAY2RGB)
                lab = cv2.cvtColor(temp_rgb, cv2.COLOR_RGB2LAB)
                clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))
                lab[:,:,0] = clahe.apply(lab[:,:,0])
                enhanced_image = cv2.cvtColor(lab, cv2.COLOR_LAB2RGB)
            else:
                logger.warning("ì´ë¯¸ì§€ í–¥ìƒ: ì˜ˆìƒì¹˜ ëª»í•œ ì´ë¯¸ì§€ ì±„ë„ ìˆ˜. CLAHE ê±´ë„ˆëœ€.")
                if len(image.shape) == 2:
                    enhanced_image = cv2.cvtColor(image, cv2.COLOR_GRAY2RGB)
            
            # ë…¸ì´ì¦ˆ ì œê±°
            if len(enhanced_image.shape) == 3 and enhanced_image.shape[2] == 3:
                enhanced_image = cv2.bilateralFilter(enhanced_image, 9, 75, 75)
            else:
                logger.warning("ë…¸ì´ì¦ˆ ì œê±°: ì´ë¯¸ì§€ ì±„ë„ì´ 3ê°œê°€ ì•„ë‹˜. bilateralFilter ê±´ë„ˆëœ€.")
            
            # ìƒ¤í”„ë‹ í•„í„° ì ìš©
            if len(enhanced_image.shape) == 3 and enhanced_image.shape[2] == 3:
                kernel = np.array([[-1,-1,-1], [-1, 9,-1], [-1,-1,-1]])
                enhanced_image = cv2.filter2D(enhanced_image, -1, kernel)
            else:
                logger.warning("ìƒ¤í”„ë‹: ì´ë¯¸ì§€ ì±„ë„ì´ 3ê°œê°€ ì•„ë‹˜. filter2D ê±´ë„ˆëœ€.")
            
            return enhanced_image
            
        except Exception as e:
            logger.warning(f"ì´ë¯¸ì§€ í–¥ìƒ ì²˜ë¦¬ ì‹¤íŒ¨: {str(e)}")
            logger.warning(traceback.format_exc())
            return image

    
    def _preprocess_image(self, image):
        """SSD300 ì…ë ¥ì„ ìœ„í•œ ì´ë¯¸ì§€ ì „ì²˜ë¦¬"""
        try:
            original_height, original_width = image.shape[:2]
            
            # OpenCV BGRì„ RGBë¡œ ë³€í™˜ (PILë¡œ ë„˜ì–´ê°€ê¸° ì „ì—)
            if len(image.shape) == 3 and image.shape[2] == 3:
                image_for_pil = cv2.cvtColor(image, cv2.COLOR_BGR2RGB) 
            elif len(image.shape) == 2: # ê·¸ë ˆì´ìŠ¤ì¼€ì¼ì¸ ê²½ìš°
                image_for_pil = cv2.cvtColor(image, cv2.COLOR_GRAY2RGB)
            else:
                image_for_pil = image # ì´ë¯¸ 3ì±„ë„ì´ë©´ ê·¸ëŒ€ë¡œ ì‚¬ìš©
            
            transform = transforms.Compose([
                transforms.ToPILImage(),
                transforms.Resize((self.input_size, self.input_size)),
                transforms.ToTensor(),
            ])
            
            input_tensor = transform(image_for_pil).unsqueeze(0).to(self.device)
            
            return input_tensor, (original_width, original_height)
            
        except Exception as e:
            logger.error(f"ì´ë¯¸ì§€ ì „ì²˜ë¦¬ ì‹¤íŒ¨: {str(e)}")
            logger.error(traceback.format_exc())
            return None, None
    
    def _run_inference(self, input_tensor):
        """SSD300 ëª¨ë¸ ì¶”ë¡  ì‹¤í–‰"""
        try:
            if self.model is None:
                raise ValueError("ëª¨ë¸ì´ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            
            logger.info(f"ğŸ¯ SSD ì¶”ë¡  ì‹œì‘ - ì…ë ¥ í¬ê¸°: {input_tensor.shape}")
            
            self.model.eval()
            with torch.no_grad():
                predictions = self.model(input_tensor)
            
            return predictions
            
        except Exception as e:
            logger.error(f"ëª¨ë¸ ì¶”ë¡  ì‹¤íŒ¨: {str(e)}")
            logger.error(traceback.format_exc())
            return None

    # ğŸ”¥ ìƒˆë¡œ ì¶”ê°€ëœ í•„í„°ë§ í•¨ìˆ˜ë“¤
    def _calculate_iou(self, box1, box2):
        """ë‘ bounding boxì˜ IoU(Intersection over Union) ê³„ì‚°"""
        # box format: {'x': x, 'y': y, 'width': w, 'height': h}
        
        x1_1, y1_1 = box1.get('x', 0), box1.get('y', 0)
        x2_1, y2_1 = x1_1 + box1.get('width', 0), y1_1 + box1.get('height', 0)
        
        x1_2, y1_2 = box2.get('x', 0), box2.get('y', 0)
        x2_2, y2_2 = x1_2 + box2.get('width', 0), y1_2 + box2.get('height', 0)
        
        # êµì§‘í•© ì˜ì—­ ê³„ì‚°
        x1_inter = max(x1_1, x1_2)
        y1_inter = max(y1_1, y1_2)
        x2_inter = min(x2_1, x2_2)
        y2_inter = min(y2_1, y2_2)
        
        if x2_inter <= x1_inter or y2_inter <= y1_inter:
            return 0.0
        
        intersection = (x2_inter - x1_inter) * (y2_inter - y1_inter)
        
        # í•©ì§‘í•© ì˜ì—­ ê³„ì‚°
        area1 = (x2_1 - x1_1) * (y2_1 - y1_1)
        area2 = (x2_2 - x1_2) * (y2_2 - y1_2)
        union = area1 + area2 - intersection
        
        return intersection / union if union > 0 else 0.0

    def _apply_ssd_filtering(self, detections):
        """
        SSD ê²€ì¶œ ê²°ê³¼ í•„í„°ë§
        - confidence >= 0.4
        - Normal í´ë˜ìŠ¤ ì œê±°
        - NMS ì ìš© (IoU threshold 0.3)
        - ê°™ì€ ë¼ë²¨ì€ confidence ê°€ì¥ ë†’ì€ ê²ƒë§Œ ì„ íƒ
        """
        if not detections:
            return []
            
        logger.info(f"ğŸ” SSD í•„í„°ë§ ì‹œì‘: {len(detections)}ê°œ detection")
            
        # 1. ì‹ ë¢°ë„ ì„ê³„ê°’ í•„í„°ë§ (0.4)
        filtered_by_conf = [
            det for det in detections 
            if det.get('confidence', 0) >= 0.5
        ]
        logger.info(f"âœ… ì‹ ë¢°ë„ 0.5 ì´ìƒ: {len(filtered_by_conf)}ê°œ")
            
        # 2. Normal í´ë˜ìŠ¤ ì œê±°
        filtered_by_label = [
            det for det in filtered_by_conf 
            if det.get('label', '').lower() != 'normal'
        ]
        logger.info(f"âœ… Normal í´ë˜ìŠ¤ ì œê±° í›„: {len(filtered_by_label)}ê°œ")
            
        if not filtered_by_label:
            logger.info("âš ï¸ ëª¨ë“  detectionì´ í•„í„°ë§ë¨")
            return []
            
        # 3. ì‹ ë¢°ë„ ìˆœìœ¼ë¡œ ì •ë ¬ (ë†’ì€ ìˆœ)
        sorted_detections = sorted(
            filtered_by_label, 
            key=lambda x: x.get('confidence', 0), 
            reverse=True
        )
            
        # 4. NMS ì ìš© (IoU threshold 0.3)
        keep_indices = []
        suppressed = set()
            
        for i, det_i in enumerate(sorted_detections):
            if i in suppressed:
                continue
                    
            keep_indices.append(i)
                    
            # í˜„ì¬ detectionê³¼ ê²¹ì¹˜ëŠ” ê²ƒë“¤ ì°¾ì•„ì„œ ì œê±°
            for j, det_j in enumerate(sorted_detections[i+1:], i+1):
                if j in suppressed:
                    continue
                    
                # IoU ê³„ì‚°
                iou = self._calculate_iou(det_i.get('bbox', {}), det_j.get('bbox', {}))
                    
                if iou > 0.3:  # IoU threshold
                    conf_i = det_i.get('confidence', 0)
                    conf_j = det_j.get('confidence', 0)
                        
                    if conf_i >= conf_j:  # iê°€ ë” ë†’ê±°ë‚˜ ê°™ì€ ì‹ ë¢°ë„ â†’ j ì œê±°
                        suppressed.add(j)
                        logger.info(f"ğŸš« ì œê±°: {det_j.get('label')} (conf:{conf_j:.3f}) â† IoU:{iou:.3f} â†’ ìœ ì§€: {det_i.get('label')} (conf:{conf_i:.3f})")
            
        # 5. NMS ê²°ê³¼
        nms_detections = [sorted_detections[i] for i in keep_indices]
        
        # ğŸ”¥ 6. ê°™ì€ ë¼ë²¨ì€ confidence ê°€ì¥ ë†’ì€ ê²ƒë§Œ ì„ íƒ
        label_best = {}
        for det in nms_detections:
            label = det.get('label', '')
            confidence = det.get('confidence', 0)
            
            if label not in label_best or confidence > label_best[label]['confidence']:
                label_best[label] = det
                logger.info(f"ğŸ“ ë¼ë²¨ '{label}' ìµœê³  confidence ì—…ë°ì´íŠ¸: {confidence:.3f}")
        
        # 7. ìµœì¢… ê²°ê³¼: ë¼ë²¨ë³„ ìµœê³  confidenceë§Œ
        final_detections = list(label_best.values())
        
        logger.info(f"âœ… SSD í•„í„°ë§ ì™„ë£Œ: {len(detections)}ê°œ â†’ NMS:{len(nms_detections)}ê°œ â†’ ë¼ë²¨ì¤‘ë³µì œê±°:{len(final_detections)}ê°œ")
            
        # 8. ê²°ê³¼ ìš”ì•½ ë¡œê·¸
        if final_detections:
            logger.info("ğŸ“‹ ìµœì¢… SSD detection ìš”ì•½:")
            for i, det in enumerate(final_detections):
                label = det.get('label', 'Unknown')
                conf = det.get('confidence', 0)
                logger.info(f"  {i+1}. {label} (ì‹ ë¢°ë„: {conf:.3f})")
            
        return final_detections

    def _parse_ssd_outputs(self, predictions, original_size):
        """SSD300 ì¶œë ¥ íŒŒì‹± ë° ai_service.py í˜•ì‹ì— ë§ê²Œ ë³€í™˜ + í•„í„°ë§ ì ìš©"""
        detections = []
        try:
            original_width, original_height = original_size
            
            if not predictions or len(predictions) == 0:
                logger.info("ëª¨ë¸ ì˜ˆì¸¡ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
                return detections
                
            pred = predictions[0] # ì²« ë²ˆì§¸ ì´ë¯¸ì§€ì— ëŒ€í•œ ì˜ˆì¸¡ ê²°ê³¼
            
            if not isinstance(pred, dict):
                logger.warning(f"ì˜ˆìƒì¹˜ ëª»í•œ ì˜ˆì¸¡ í˜•íƒœ: {type(pred)}. ë”•ì…”ë„ˆë¦¬ê°€ ì•„ë‹™ë‹ˆë‹¤.")
                return detections
                
            boxes = pred.get('boxes', torch.empty((0, 4)))
            labels = pred.get('labels', torch.empty((0,)))
            scores = pred.get('scores', torch.empty((0,)))
            
            logger.info(f"ğŸ“Š SSD ì›ë³¸ ì¶œë ¥: boxes={boxes.shape}, labels={labels.shape}, scores={scores.shape}")
            
            if len(boxes) == 0:
                logger.info("ê²€ì¶œëœ ê°ì²´ ì—†ìŒ.")
                return detections
                
            # ğŸ”¥ ì„ê³„ê°’ì„ ë‚®ê²Œ í•´ì„œ ì¼ë‹¨ ëª¨ë“  ê²€ì¶œ ìˆ˜ì§‘ (í•„í„°ë§ì—ì„œ ì²˜ë¦¬)
            valid_indices = scores > self.confidence_threshold  # 0.1ë¡œ ëª¨ë“  ê²€ì¶œ ìˆ˜ì§‘
            valid_boxes = boxes[valid_indices]
            valid_labels = labels[valid_indices]
            valid_scores = scores[valid_indices]
            
            logger.info(f"ğŸ” ê¸°ë³¸ ì„ê³„ê°’ {self.confidence_threshold} ì´ìƒ: {len(valid_boxes)}ê°œ")
            
            scale_x = original_width / self.input_size
            scale_y = original_height / self.input_size
            
            for i in range(len(valid_boxes)):
                box = valid_boxes[i].cpu().numpy().tolist()
                label_id = int(valid_labels[i].cpu().numpy().item())
                score = float(valid_scores[i].cpu().numpy().item())
                
                x1, y1, x2, y2 = box
                
                orig_x1 = int(x1 * scale_x)
                orig_y1 = int(y1 * scale_y)
                orig_x2 = int(x2 * scale_x)
                orig_y2 = int(y2 * scale_y)
                
                orig_x1 = max(0, min(orig_x1, original_width))
                orig_y1 = max(0, min(orig_y1, original_height))
                orig_x2 = max(0, min(orig_x2, original_width))
                orig_y2 = max(0, min(orig_y2, original_height))
                
                if orig_x2 > orig_x1 + 5 and orig_y2 > orig_y1 + 5:
                    class_name = self.class_names.get(label_id, f'Unknown_class_{label_id}')
                    
                    detection_item = {
                        'bbox': {
                            'x': float(orig_x1),
                            'y': float(orig_y1),
                            'width': float(orig_x2 - orig_x1),
                            'height': float(orig_y2 - orig_y1)
                        },
                        'confidence': score,
                        'label': class_name,
                        'confidence_score': score,
                        'ai_text': f'SSD300 ê²€ì¶œ: {class_name} (ì •í™•ë„: {score:.3f})',
                        'area': float((orig_x2 - orig_x1) * (orig_y2 - orig_y1)),
                        # í•´ìƒë„ ì •ë³´ ì¶”ê°€
                        'image_width': original_width,
                        'image_height': original_height,
                    }
                    
                    detection_item['medical_info'] = self._extract_medical_features(detection_item, (original_height, original_width))
                    detections.append(detection_item)
            
            logger.info(f"âœ… SSD ì›ë³¸ ê²€ì¶œ ì™„ë£Œ: {len(detections)}ê°œ")
            
            # ğŸ”¥ í•„í„°ë§ ì ìš©
            filtered_detections = self._apply_ssd_filtering(detections)
            
            return filtered_detections
            
        except Exception as e:
            logger.error(f"SSD ì¶œë ¥ íŒŒì‹± ì‹¤íŒ¨: {e}")
            logger.error(f"ìƒì„¸ ì—ëŸ¬: {traceback.format_exc()}")
            return []
    
    def _extract_medical_features(self, detection, image_shape):
        """ì˜ë£Œ ì˜ìƒ íŠ¹í™” íŠ¹ì§• ì¶”ì¶œ"""
        try:
            height, width = image_shape # image_shapeëŠ” (height, width)
            bbox = detection['bbox'] # bboxëŠ” {x, y, width, height} í˜•ì‹
            
            center_x = (bbox['x'] + bbox['width'] / 2) / width
            center_y = (bbox['y'] + bbox['height'] / 2) / height
            
            area_ratio = detection['area'] / (width * height)
            
            aspect_ratio = bbox['width'] / bbox['height'] if bbox['height'] > 0 else 0
            
            anatomical_region = self._determine_anatomical_region(center_x, center_y)
            
            return {
                'relative_position': {
                    'center_x': center_x,
                    'center_y': center_y
                },
                'size_metrics': {
                    'area_ratio': area_ratio,
                    'aspect_ratio': aspect_ratio,
                    'is_large_finding': area_ratio > 0.1,  
                    'is_elongated': aspect_ratio > 2.0 or aspect_ratio < 0.5
                },
                'anatomical_info': {
                    'region': anatomical_region,
                    'is_central': 0.3 < center_x < 0.7 and 0.3 < center_y < 0.7,
                    'quadrant': self._get_quadrant(center_x, center_y)
                },
                'clinical_relevance': {
                    'attention_score': min(area_ratio * 10 + detection['confidence'], 1.0),
                    'priority_level': 'high' if area_ratio > 0.1 else 'medium' if area_ratio > 0.05 else 'low'
                }
            }
            
        except Exception as e:
            logger.warning(f"ì˜ë£Œ íŠ¹ì§• ì¶”ì¶œ ì‹¤íŒ¨: {str(e)}")
            logger.warning(traceback.format_exc())
            return {}
    
    def _determine_anatomical_region(self, center_x, center_y):
        """í•´ë¶€í•™ì  ìœ„ì¹˜ ê²°ì •"""
        positions = []
        
        if center_x < 0.33:
            positions.append('left')
        elif center_x > 0.67:
            positions.append('right')
        else:
            positions.append('center')
        
        if center_y < 0.33:
            positions.append('upper')
        elif center_y > 0.67:
            positions.append('lower')
        else:
            positions.append('middle')
        
        return '_'.join(positions)
    
    def _get_quadrant(self, center_x, center_y):
        """ì‚¬ë¶„ë©´ ê²°ì •"""
        if center_x < 0.5 and center_y < 0.5:
            return 'upper_left'
        elif center_x >= 0.5 and center_y < 0.5:
            return 'upper_right'
        elif center_x < 0.5 and center_y >= 0.5:
            return 'lower_left'
        else:
            return 'lower_right'

    def analyze(self, dicom_data_bytes):
        """DICOM ì´ë¯¸ì§€ ë¶„ì„ ë©”ì¸ í•¨ìˆ˜"""
        try:
            start_time = datetime.now()
            
            if self.model is None:
                logger.error("SSD300 ëª¨ë¸ì´ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ë¶„ì„ì„ ìˆ˜í–‰í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                return {
                    'success': False,
                    'error': 'SSD300 ëª¨ë¸ì´ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.',
                    'detections': []
                }
            
            # DICOM ì´ë¯¸ì§€ ë¡œë“œ
            image, dicom_dataset = self._load_dicom_from_bytes(dicom_data_bytes)
            if image is None:
                return {
                    'success': False,
                    'error': 'DICOM ì´ë¯¸ì§€ë¥¼ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.',
                    'detections': []
                }
            
            # ì˜ë£Œ ì˜ìƒ í–¥ìƒ
            enhanced_image = self._enhance_medical_image(image)
            
            # ì´ë¯¸ì§€ ì „ì²˜ë¦¬
            input_tensor, original_size = self._preprocess_image(enhanced_image)
            if input_tensor is None:
                return {
                    'success': False,
                    'error': 'ì´ë¯¸ì§€ ì „ì²˜ë¦¬ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.',
                    'detections': []
                }
            
            # ëª¨ë¸ ì¶”ë¡ 
            predictions = self._run_inference(input_tensor)
            if predictions is None:
                return {
                    'success': False,
                    'error': 'ëª¨ë¸ ì¶”ë¡ ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.',
                    'detections': []
                }
            
            # ê²°ê³¼ íŒŒì‹± (í•´ìƒë„ ì •ë³´ í¬í•¨) + í•„í„°ë§ ì ìš©
            detections = self._parse_ssd_outputs(predictions, original_size)
            
            # ì²˜ë¦¬ ì‹œê°„ ê³„ì‚°
            processing_time = (datetime.now() - start_time).total_seconds()
            
            # DICOM ë©”íƒ€ë°ì´í„° ì¶”ì¶œ
            dicom_info = {}
            original_width, original_height = original_size
            
            if dicom_dataset:
                try:
                    # DICOMì—ì„œ ì§ì ‘ í•´ìƒë„ ì¶”ì¶œ (ë” ì •í™•í•  ìˆ˜ ìˆìŒ)
                    dicom_width = int(getattr(dicom_dataset, 'Columns', 0))
                    dicom_height = int(getattr(dicom_dataset, 'Rows', 0))
                    
                    # DICOMì—ì„œ ì¶”ì¶œí•œ í•´ìƒë„ê°€ ìœ íš¨í•˜ë©´ ìš°ì„  ì‚¬ìš©
                    if dicom_width > 0 and dicom_height > 0:
                        original_width = dicom_width
                        original_height = dicom_height
                    
                    dicom_info = {
                        'patient_id': str(getattr(dicom_dataset, 'PatientID', 'Unknown')),
                        'study_date': str(getattr(dicom_dataset, 'StudyDate', 'Unknown')),
                        'modality': str(getattr(dicom_dataset, 'Modality', 'UNKNOWN')),
                        'body_part': str(getattr(dicom_dataset, 'BodyPartExamined', 'Unknown')),
                        'image_size': {
                            'width': original_width,
                            'height': original_height
                        }
                    }
                except Exception as e:
                    logger.warning(f"DICOM ë©”íƒ€ë°ì´í„° ì¶”ì¶œ ì‹¤íŒ¨: {str(e)}")
            
            # ğŸ”¥ ê²°ê³¼ì— í•´ìƒë„ ì •ë³´ ëª…ì‹œì ìœ¼ë¡œ ì¶”ê°€
            result = {
                'success': True,
                'detections': detections,
                # ğŸ”¥ ìµœìƒìœ„ ë ˆë²¨ì— í•´ìƒë„ ì •ë³´ ì¶”ê°€ (Djangoì—ì„œ ì‰½ê²Œ ì ‘ê·¼ ê°€ëŠ¥)
                'image_width': original_width,
                'image_height': original_height,
                'analysis_info': {
                    'model_type': 'SSD300',
                    'device': str(self.device),
                    'processing_time_seconds': processing_time,
                    'detection_count': len(detections),
                    'confidence_threshold': 0.4,  # ì‹¤ì œ í•„í„°ë§ì— ì‚¬ìš©ëœ ì„ê³„ê°’
                    'input_size': self.input_size,
                    'filtering_applied': True,  # í•„í„°ë§ì´ ì ìš©ë˜ì—ˆìŒì„ ëª…ì‹œ
                    'nms_iou_threshold': 0.3
                },
                'dicom_info': dicom_info,
                'image_info': {
                    'original_shape': image.shape,
                    'processed_shape': enhanced_image.shape,
                    # ğŸ”¥ ì—¬ê¸°ì—ë„ í•´ìƒë„ ì •ë³´ ì¶”ê°€
                    'original_width': original_width,
                    'original_height': original_height,
                    'processed_width': enhanced_image.shape[1],
                    'processed_height': enhanced_image.shape[0],
                    'input_size': self.input_size,  # SSD ëª¨ë¸ ì…ë ¥ í¬ê¸°ë„ í¬í•¨
                    'scale_factors': {
                        'scale_x': original_width / self.input_size,
                        'scale_y': original_height / self.input_size
                    }
                },
                'message': f"SSD ë¶„ì„ ì™„ë£Œ: {len(detections)}ê°œ ê²€ì¶œ (í•„í„°ë§ ì ìš©), í•´ìƒë„: {original_width}x{original_height}"
            }
            
            logger.info(f"âœ… SSD ë¶„ì„ ì™„ë£Œ: {len(detections)}ê°œ ê²€ì¶œ, ì²˜ë¦¬ì‹œê°„: {processing_time:.2f}ì´ˆ, í•´ìƒë„: {original_width}x{original_height}")
            return result
            
        except Exception as e:
            logger.error(f"âŒ SSD ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            logger.error(f"âŒ ìƒì„¸ ì—ëŸ¬: {traceback.format_exc()}")
            return {
                'success': False,
                'error': str(e),
                'detections': []
            }

# ì „ì—­ ë¶„ì„ê¸° ì¸ìŠ¤í„´ìŠ¤
_analyzer = None

def get_analyzer():
    """ì „ì—­ ë¶„ì„ê¸° ì¸ìŠ¤í„´ìŠ¤ ë°˜í™˜"""
    global _analyzer
    if _analyzer is None:
        _analyzer = SSDAnalyzer()
    return _analyzer

def analyze(dicom_data): 
    """ì™¸ë¶€ì—ì„œ í˜¸ì¶œí•˜ëŠ” ë¶„ì„ í•¨ìˆ˜"""
    analyzer = get_analyzer()
    return analyzer.analyze(dicom_data)